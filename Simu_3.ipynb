{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7aaeb1-aada-4c75-87eb-d27ba6ae81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from joblib import Parallel, delayed\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from itertools import product\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163ff8d-056b-4fd7-a3fd-cabf756bc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from M_GWXGB_1 import GeoWeightedXGBoostTrainer, GeoWeightedXGBoostInterpreter, GeoWeightedXGBoostPredictor, M_GWXGB_Initial, OptimizedBandwidth, M_GXGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae8a19-2e3b-4613-a9da-c2a7ff75f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e77237-8e74-4f09-b2f0-f1a83130ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadbdf9e-0cc6-4247-bdb3-949ab948b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ad9f4-cda6-40a6-bf31-ec5748fe38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 25\n",
    "mpl.rcParams['axes.unicode_minus'] = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1f6bb-acae-4e9d-8cf9-0f66281f299d",
   "metadata": {},
   "source": [
    "# Function defination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101ca58-5136-4716-a051-125cd73274ec",
   "metadata": {},
   "source": [
    "## Adj_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae44170-f246-477b-aa52-4a56e363a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r2_score(y_true, y_pred, n_features):\n",
    "    n_samples = len(y_true)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    if n_samples <= n_features + 1:\n",
    "        raise ValueError(\" \")\n",
    "    \n",
    "    adjusted_r2 = 1 - (1 - r2) * (n_samples - 1) / (n_samples - n_features - 1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d11025",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9752ea-e7cf-412b-8b90-faadfec4f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50\n",
    "def moving_wind(f1_est,X1,w=2):\n",
    "    mat = np.zeros((size,size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if i == 0 and j == 0:\n",
    "                top = f1_est.reshape(size,size)[0:w,0:w]\n",
    "                bot = X1.reshape(size,size)[0:w,0:w]\n",
    "                \n",
    "            if i == 0 and j > 0:\n",
    "                top = f1_est.reshape(size,size)[0:i+w,j-1:j+w]\n",
    "                bot = X1.reshape(size,size)[0:i+w,j-1:j+w]\n",
    "                \n",
    "            if j == 0 and i > 0:\n",
    "                top = f1_est.reshape(size,size)[i-1:i+w,0:j+w]\n",
    "                bot = X1.reshape(size,size)[i-1:i+w,0:j+w]\n",
    "                \n",
    "            if i > 0 and j > 0 : \n",
    "                top = f1_est.reshape(size,size)[i-1:i+w,j-1:j+w]\n",
    "                bot = X1.reshape(size,size)[i-1:i+w,j-1:j+w]\n",
    "            \n",
    "            m = np.linalg.lstsq(bot.reshape(-1,1), top.reshape(-1,1), rcond=None)[0][0,0]\n",
    "            if m > size:\n",
    "                print(i,j)\n",
    "            mat[i,j] = m\n",
    "            \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88294994-b096-4b40-9cf7-dfc09b78d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.matplotlib import Inferno_3\n",
    "\n",
    "def plot_1(b,title,vmin=None,vmax=None):\n",
    "    size = 50\n",
    "    plt.figure(figsize=(6, 4), dpi=300)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(b.reshape(size,size),vmin=vmin, vmax=vmax, cmap=Inferno_3.mpl_colormap)\n",
    "    plt.title(title,fontsize=25)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9397b-1d7b-4ee7-968f-1e88ef095622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08f0d9d0-4aef-4e26-b272-1c2bde86f75c",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca554f8-9b0d-44ec-bf6c-a6e7b456ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50\n",
    "\n",
    "X1 = np.random.uniform(-1.5,1.5,size*size)\n",
    "X2 = np.random.uniform(-1.5,1.5,size*size)\n",
    "X3 = np.random.uniform(-1.5,1.5,size*size)\n",
    "X4 = np.random.uniform(-1.5,1.5,size*size)\n",
    "X5 = np.zeros((size,size))\n",
    "\n",
    "for i in range(size):\n",
    "    for j in range(size):\n",
    "        X5[i][j] = 3/(12.5**4)*(12.5**2-(12.5-i/2)**2)*(12.5**2-(12.5-j/2)**2)+0.1\n",
    "X = np.vstack([X1, X2, X3, X4, X5.reshape(-1)]).T\n",
    "\n",
    "b0 = np.zeros((size,size))\n",
    "b1 = np.zeros((size,size))\n",
    "b3 = np.zeros((size,size))\n",
    "\n",
    "for i in range(size):\n",
    "    for j in range(size):\n",
    "        b0[i][j] = 2\n",
    "\n",
    "for i in range(size):\n",
    "    for j in range(size):\n",
    "        b1[i][j] = 2\n",
    "        \n",
    "for i in range(size):\n",
    "    for j in range(size):\n",
    "        b3[i][j] = math.cos(math.pi*math.exp(i/50))*math.sin(math.pi*math.exp(j/50))*3\n",
    "\n",
    "u = np.array([np.linspace(0,size-1,num=size)]*size).reshape(-1)\n",
    "v = np.array([np.linspace(0,size-1,num=size)]*size).T.reshape(-1)\n",
    "coords = np.array(list(zip(u,v)))\n",
    "\n",
    "f0 = b0.reshape(-1)\n",
    "f1 = 2*X1\n",
    "f2 = X2**3\n",
    "f3 = b3.reshape(-1)*X3.reshape(-1)\n",
    "\n",
    "f4 = np.zeros_like(X4)\n",
    "mask_left = u < (size / 2)\n",
    "mask_right = ~mask_left\n",
    "\n",
    "f4[mask_left] = X4[mask_left] ** 3\n",
    "f4[mask_right] = -X4[mask_right] ** 3\n",
    "\n",
    "f5 = np.log(X5.reshape(-1)/2)*X5.reshape(-1)\n",
    "fs = np.vstack([f1, f2, f3, f4, f5]).T\n",
    "err = np.random.uniform(-1.5,1.5,size*size)\n",
    "y = (f0 + f1 + f2 + f3 + f4 + f5 + err).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c1ec6-4b2e-4147-9dd8-46cfba428c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input the figure saving path\n",
    "\n",
    "save_path= r'...\\\\Simu3_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ef360-e1c3-47bc-976b-1562964df908",
   "metadata": {},
   "outputs": [],
   "source": [
    "## actual parameter surfaces\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(fs[:, i] / X[:, i], fr'actual: $f_{i+1} $')\n",
    "    \n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'actual_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a56f9-302c-4baa-bc08-ad4834a17936",
   "metadata": {},
   "outputs": [],
   "source": [
    "## actual non-linear relationships\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    plt.ylabel(rf'$f_{i+1} X_{i+1} \\sim X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "    \n",
    "    plt.savefig(save_path + '\\\\' + rf'true_f{i+1}_nl.jpg',\n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c12248-0328-48ca-8ab8-464eeba4ddc7",
   "metadata": {},
   "source": [
    "# XGBoost model\n",
    "5 fold cross-validation is used to form a complete prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc120cd4-0bec-45a9-a38e-46e7117fd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostTrainer_1:\n",
    "    def __init__(self, n_splits=5, random_state=42, n_jobs=-1):\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.oof_predictions = None\n",
    "        self.cv_scores = []\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.best_iterations_per_fold = []\n",
    "        self.oof_shap_values = None\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def _train_fold(self, params, X, y, train_idx, val_idx, fold_num):\n",
    "\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        dtrain_fold = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "        dvalid_fold = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "\n",
    "        watchlist = [(dvalid_fold, 'eval')]\n",
    "\n",
    "        model = xgb.train(params,\n",
    "                         dtrain_fold,\n",
    "                         num_boost_round=1000,\n",
    "                         evals=watchlist,\n",
    "                         early_stopping_rounds=30,\n",
    "                         verbose_eval=False)\n",
    "\n",
    "        return {\n",
    "            'fold_num': fold_num,\n",
    "            'score': model.best_score,\n",
    "            'model': model,\n",
    "            'val_idx': val_idx\n",
    "        }\n",
    "\n",
    "    def objective(self, params, X, y):\n",
    "        params['max_depth'] = int(params['max_depth'])\n",
    "        params['min_child_weight'] = int(params['min_child_weight'])\n",
    "\n",
    "        param_use = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            **params\n",
    "        }\n",
    "\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        folds = list(kf.split(X, y))\n",
    "\n",
    "        results = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._train_fold)(\n",
    "                param_use, X, y, train_idx, val_idx, fold_num\n",
    "            )\n",
    "            for fold_num, (train_idx, val_idx) in enumerate(folds)\n",
    "        )\n",
    "\n",
    "        cv_scores = [res['score'] for res in results]\n",
    "        avg_cv_score = np.mean(cv_scores)\n",
    "        \n",
    "        return {'loss': avg_cv_score, 'status': STATUS_OK}\n",
    "\n",
    "    def _cv_fold(self, X, y, train_idx, val_idx, fold_num):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        dtrain_fold = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "        dvalid_fold = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "\n",
    "        watchlist = [(dtrain_fold, 'train'), (dvalid_fold, 'eval')]\n",
    "\n",
    "        fold_model = xgb.train(self.best_params,\n",
    "                             dtrain_fold,\n",
    "                             num_boost_round=2000,\n",
    "                             evals=watchlist,\n",
    "                             early_stopping_rounds=50,\n",
    "                             verbose_eval=100 if fold_num == 0 else False)\n",
    "\n",
    "        best_iteration = fold_model.best_iteration\n",
    "        fold_score = fold_model.best_score\n",
    "\n",
    "        oof_preds_fold = fold_model.predict(dvalid_fold, iteration_range=(0, best_iteration))\n",
    "        \n",
    "        fold_explainer = shap.TreeExplainer(fold_model)\n",
    "        fold_shap_value = fold_explainer.shap_values(dvalid_fold)\n",
    "\n",
    "        return {\n",
    "            'fold_num': fold_num,\n",
    "            'best_iteration': best_iteration,\n",
    "            'score': fold_score,\n",
    "            'val_idx': val_idx,\n",
    "            'oof_pred': oof_preds_fold,\n",
    "            'shap_values': fold_shap_value,\n",
    "            'model': fold_model\n",
    "        }\n",
    "\n",
    "    def calcu_oof_and_shap(self, X, y, tune=True, max_evals=50):\n",
    "        if y.ndim > 1 and y.shape[1] == 1:\n",
    "            y = y.ravel()\n",
    "            \n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "\n",
    "        if tune or self.best_params is None:\n",
    "            self.tune_params(X, y, max_evals=max_evals)\n",
    "        elif not tune and self.best_params is None:\n",
    "            raise ValueError(\"Cannot train without tuning if best_params are not already set.\")\n",
    "\n",
    "        print(f\"\\nStarting {self.n_splits}-Fold CV for OOF predictions (parallel)...\")\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        folds = list(kf.split(X, y))\n",
    "\n",
    "        self.oof_predictions = np.zeros(X.shape[0])\n",
    "        self.oof_shap_values = np.zeros(X.shape)\n",
    "        self.cv_scores = []\n",
    "        self.best_iterations_per_fold = []\n",
    "\n",
    "        results = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._cv_fold)(X, y, train_idx, val_idx, fold_num)\n",
    "            for fold_num, (train_idx, val_idx) in enumerate(folds)\n",
    "        )\n",
    "\n",
    "        for res in results:\n",
    "            self.best_iterations_per_fold.append(res['best_iteration'])\n",
    "            self.cv_scores.append(res['score'])\n",
    "            self.oof_predictions[res['val_idx']] = res['oof_pred']\n",
    "            self.oof_shap_values[res['val_idx']] = res['shap_values']\n",
    "\n",
    "        oof_rmse = np.sqrt(mean_squared_error(y, self.oof_predictions))\n",
    "        oof_r2 = adjusted_r2_score(y, self.oof_predictions, X.shape[1])\n",
    "        \n",
    "        print(\"\\n--- Training Final Model on Full Data ---\")\n",
    "        final_num_boost_round = int(np.median(self.best_iterations_per_fold))\n",
    "        dfull = xgb.DMatrix(X, label=y)\n",
    "\n",
    "        self.best_model = xgb.train(self.best_params,\n",
    "                                  dfull,\n",
    "                                  num_boost_round=final_num_boost_round,\n",
    "                                  verbose_eval=100)\n",
    "\n",
    "        print(\"Final model training complete.\")\n",
    "        return self.best_model, self.oof_predictions, oof_rmse, oof_r2, self.oof_shap_values\n",
    "\n",
    "    def tune_params(self, X, y, max_evals=50):\n",
    "        search_space = {\n",
    "            \"max_depth\": hp.quniform('max_depth', 3, 8, 1),\n",
    "            \"learning_rate\": hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "            \"subsample\": hp.uniform('subsample', 0.6, 1.0),\n",
    "            \"colsample_bytree\": hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "            \"min_child_weight\": hp.quniform('min_child_weight', 1, 6, 1),\n",
    "            \"gamma\": hp.uniform('gamma', 0, 0.5),\n",
    "            \"reg_alpha\": hp.loguniform('reg_alpha', np.log(0.001), np.log(1.0)),\n",
    "            \"reg_lambda\": hp.loguniform('reg_lambda', np.log(0.1), np.log(10.0)),\n",
    "        }\n",
    "\n",
    "        trials = Trials()\n",
    "        best = fmin(\n",
    "            fn=lambda params: self.objective(params, X, y),\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(self.random_state)\n",
    "        )\n",
    "\n",
    "        self.best_params = {\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'subsample': best['subsample'],\n",
    "            'colsample_bytree': best['colsample_bytree'],\n",
    "            'min_child_weight': int(best['min_child_weight']),\n",
    "            'gamma': best['gamma'],\n",
    "            'reg_alpha': best['reg_alpha'],\n",
    "            'reg_lambda': best['reg_lambda'],\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        print(\"\\nBest parameters found:\")\n",
    "        print(self.best_params)\n",
    "        return self.best_params\n",
    "\n",
    "    def predict(self, X):\n",
    "        dmatrix = xgb.DMatrix(X)\n",
    "        return self.best_model.predict(dmatrix)\n",
    "\n",
    "    def compute_shap_values(self, X):\n",
    "        explainer = shap.TreeExplainer(self.best_model)\n",
    "        dmatrix = xgb.DMatrix(X)\n",
    "        return explainer.shap_values(dmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b6867",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b987b-8143-432c-9de4-30a63fb0da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X_1 = np.concatenate((X, coords), axis=1)\n",
    "xgb_trainer = XGBoostTrainer_1(n_splits=5, random_state=42, n_jobs=4)\n",
    "final_model, oof_preds, oof_rmse, oof_r2, oof_shap = xgb_trainer.calcu_oof_and_shap(X_1, y, tune=True, max_evals=50)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f1422-dfb0-4911-93fc-5a3d8ca25e8a",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b914f98-d268-456c-89bd-4d354b64851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: \", oof_rmse)\n",
    "print(\"adj_R2: \", adjusted_r2_score(oof_predictions, y, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6e912",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e30d7b",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a86843-a814-4014-83f3-587620abff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 0.5, -0.5, -0.5, 2]\n",
    "locs_Y = [-3.2, -3.2, -4, -3, -1.1]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                oof_shap[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(oof_shap[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['XGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'xgb_X{i+1}_nl.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca8bce-30cc-40d2-a4b8-5b6ae6f3b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local\n",
    "\n",
    "x_test = np.random.uniform(-1.5, 1.5, 2500)\n",
    "f_test = -x_test ** 3\n",
    "\n",
    "point_id = 2448\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    b = oof_shap[:, i][point_id] / X[:, i][point_id]\n",
    "    plt.scatter(x_test, \n",
    "                b*x_test,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(x_test, \n",
    "                f_test, \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(b*x_test, f_test)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['XGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'xgb_X{i+1}_nl_local_2448.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03e3da",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c805635-2ffc-4fa9-b6ee-b0f68131cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0, -3, -2.25, -3]\n",
    "vmaxs = [2.2, 3, 3, 2.25, 0.44]\n",
    "\n",
    "bws = [2500, 2, 2, 2, 2]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(moving_wind(oof_shap[:, i], X[:, i], w = bws[i]), fr'XGB: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = moving_wind(oof_shap[:, i], X[:, i]).reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'xgb_X{i+1}_s.jpg', \n",
    "                dpi = 300)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42678efa",
   "metadata": {},
   "source": [
    "# GWXGB model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa1408",
   "metadata": {},
   "source": [
    "## train model\n",
    "\n",
    "obtain the best model from 19 bandwidth (using the geographic clustering approach for searching the best bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c3eb4-e146-49dd-8ab8-5b3b7d75c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_set(target, gwxgb_trainer):\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "    test_indices_list, test_predictions_list = gwxgb_trainer.test_indices_list, gwxgb_trainer.test_predictions_list\n",
    "    for i, (test_indices, y_pred_test) in enumerate(zip(test_indices_list, test_predictions_list)):\n",
    "            \n",
    "        y_test = target[test_indices]\n",
    "        mse_score = mean_squared_error(y_test, y_pred_test)\n",
    "        mse_scores.append(mse_score)\n",
    "        r2 = r2_score(y_test, y_pred_test)\n",
    "        r2_scores.append(r2)\n",
    "    return np.mean(mse_scores), np.mean(r2_scores) if mse_scores else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e4de1-7448-4479-89df-2676c8eaef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = (125, 251, 125)\n",
    "save_dir = r'your output path'\n",
    "n_clusters = 100\n",
    "\n",
    "gwxgb_trainer = GeoWeightedXGBoostTrainer(data=X,\n",
    "                                    target=y,\n",
    "                                    locations=coords,\n",
    "                                    n_jobs=12, \n",
    "                                    use_full_sample = True)                          \n",
    "optimal_k = gwxgb_trainer.search_optimal_k_nearest(k_range)\n",
    "gwxgb_trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d48c32-1765-4166-aedc-94d2fd144bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_y_hat, y_hat = gwxgb_trainer.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4be538-4957-4eac-afff-f0ad43b2a7c2",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f800b830-7213-460e-944f-d38dcce464b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.2993776514655921\n",
      "adj_R2:  0.8171748179314405\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y, y_hat)))\n",
    "print(\"adj_R2: \", adjusted_r2_score(y, y_hat, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d849e-0d83-492b-bb22-d10813365cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea8ccce6-75ed-4bd9-9e9d-47adc73edecd",
   "metadata": {},
   "source": [
    "## SHAP calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a10ca6-8650-4f3a-8320-3a3d1aa49888",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices_list = gwxgb_trainer.test_indices_list\n",
    "interpreter = GeoWeightedXGBoostInterpreter(gwxgb_trainer, use_shap=True)\n",
    "\n",
    "shap_values_df = pd.DataFrame()\n",
    "for i, model in enumerate(gwxgb_trainer.models):\n",
    "    test_indices = test_indices_list[i]\n",
    "    X_test = X[test_indices]\n",
    "    shap_values = interpreter.calculate_shap_values(model, X_test)\n",
    "    shap_values_df_i = pd.DataFrame(shap_values, columns=[f\"shap_{j}\" for j in range(shap_values.shape[1])])\n",
    "    shap_values_df_i['original_index'] = test_indices\n",
    "    shap_values_df = pd.concat([shap_values_df, shap_values_df_i], ignore_index=True) ## local\n",
    "gwxgb_shap_global = shap_values_df.groupby('original_index')[[f\"shap_{j}\" for j in range(shap_values.shape[1])]].mean().reset_index() ## global\n",
    "\n",
    "global_shap_xs = np.array(gwxgb_shap_global[['shap_0', 'shap_1', 'shap_2', 'shap_3', 'shap_4']]).reshape(2500, 5)\n",
    "gwxgb_shap_local = shap_values_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ae27d-0e8c-47bf-b512-88ecc314745d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96aa294e",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e15f466",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1afa14-4601-480e-b837-465dbe5ac221",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 0.5, -0.5, -0.5, 2]\n",
    "locs_Y = [-3.2, -3.2, -4, -3, -0.6]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                global_shap_xs[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(global_shap_xs[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gwxgb_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe2b57-36ea-4e87-ac79-2f03ad8c8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local relationships\n",
    "locs_X = [0.5, 0.5, -0.5, 0.5, 1.25]\n",
    "locs_Y = [-3.2, -3.2, -4, -2, -0.6]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "\n",
    "point_id = 'the point id'\n",
    "vmin = point_id * optimal_k * 0.3\n",
    "vmax = (point_id+1) * optimal_k * 0.3\n",
    "\n",
    "for i in range(5):\n",
    "    nearest_indices = gwxgb_shap_local[vmin:vmax].original_index\n",
    "    point_1_shap = gwxgb_shap_local[vmin:vmax].loc[:, f'shap_{i}']\n",
    "    point_1_x3 = X[nearest_indices, i]\n",
    "    f = fs[[nearest_indices], i].reshape(-1)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "                point_1_shap,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "               f,\n",
    "               edgecolors = 'k',\n",
    "               alpha=0.6, \n",
    "               s = 3)\n",
    "\n",
    "    plt.legend(['GWXGB curve', 'Actual curve'])\n",
    "\n",
    "    r2 = r2_score(point_1_shap, f)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "    \n",
    "    plt.legend(['GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gwxgb_X{i+1}_nl_local.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ecd52",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686268f-e489-49ab-a582-0160641ada5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0, -3, -2.25, -3]\n",
    "vmaxs = [2.2, 3, 3, 2.25, 0.44]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(moving_wind(global_shap_xs[:, i], X[:, i]), fr'GWXGB: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = moving_wind(global_shap_xs[:, i], X[:, i]).reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gwxgb_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1586e9da",
   "metadata": {},
   "source": [
    "# MGWR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c047530",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef29093-a7cc-47b7-91ff-8a7143bead6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgwr.gwr import GWR, MGWR                                                   \n",
    "from mgwr.sel_bw import Sel_BW\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b572e2-6a50-4ae9-a0f4-68cf4426fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Sel_BW(coords, y, X, multi=True, constant=True, kernel='bisquare', fixed=False)\n",
    "bws = sel.search(verbose=False)\n",
    "result = MGWR(coords, y, X, selector=sel,constant=True, kernel='bisquare', fixed=False).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd0d7e-99b3-42dd-bb11-03837fa05ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162a58a",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40026c6-62ae-42d8-aecb-2bc7bbd05cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y, result.predy)))\n",
    "print(\"adj_R2: \", adjusted_r2_score(y, result.predy, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c84418",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6431435-66b2-4230-9cce-61d89a2c757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f2eda",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9ad1a-dce5-49c9-ab6f-3223715871c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 0.5, -0.5, -0.5, 2]\n",
    "locs_Y = [-3.2, -3.2, -4, -3, -0.6]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                params[:, i+1] * X[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(params[:, i+1] * X[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['MGWR curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwr_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122864b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## local relationships\n",
    "\n",
    "locs_X = [0.5, 0.5, -0.5, 0.5, 2]\n",
    "locs_Y = [-3.2, -3.2, -4, -3, -0.6]\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    n_neighbors = int(bws[i+1]) \n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', metric='euclidean')\n",
    "    nn.fit(coords)\n",
    "    distances, selected_indices_list = nn.kneighbors(coords)\n",
    "\n",
    "    nearest_indices = selected_indices_list[52]\n",
    "    \n",
    "    b = result.params[:, i+1][52]\n",
    "    f = fs[[nearest_indices], i].reshape(-1)\n",
    "    point_1_x3 = X[nearest_indices, i]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "                b*point_1_x3,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "               f,\n",
    "               edgecolors = 'k',\n",
    "               alpha=0.6, \n",
    "               s = 3)\n",
    "\n",
    "    plt.legend(['MGWR curve', 'Actual curve'])\n",
    "\n",
    "    r2 = r2_score(b*point_1_x3, f)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "    \n",
    "    plt.legend(['MGWR curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwr_X{i+1}_nl_local.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38781901",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0, -3, -2.25, -3]\n",
    "vmaxs = [2.2, 3, 3, 2.25, 0.44]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(result.params[:, i+1], fr'MGWR: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = result.params[:, i+1].reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwr_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee37790",
   "metadata": {},
   "source": [
    "# M-GWXGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f966c1",
   "metadata": {},
   "source": [
    "\n",
    "**1. we first generate the results from GWXGB under 19 bandwidth, named like 'shap_values_bw{bandwidth}_global.csv' and 'shap_values_bw{bandwidth}_local.csv' under your path, where the file ending with \"local.csv\" include the shapley values from all sub-models. and the file ending with \"global.csv\" average the output of \"local.csv\" file by the sample id**  \n",
    "**2. we permutate the shap value to generate the best prediction combination**  \n",
    "**3. use LtoG method to identify the local and global estimator**  \n",
    "**4. set the prediction combination to the initialization and use M-GWXGB to iteratively fit data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe38ea-49f7-48da-8bc1-3d5c6f4d77f1",
   "metadata": {},
   "source": [
    "## LtoG approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e01018-2e11-4aad-ab7b-3a959a07c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate prediction for each variable under each bandwidth\n",
    "bandwidths = [i for i in range(125, 2376, 125)]\n",
    "save_dir = r'....\\\\GWXGB_full'\n",
    "\n",
    "mul_gwxgb = M_GWXGB_Initial(data=X, target=y, locations=coords, bandwidths=bandwidths, \n",
    "                             use_shap=True, \n",
    "                             n_jobs=20, \n",
    "                             shap_save_dir=save_dir)\n",
    "\n",
    "mul_gwxgb.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86124407-9adc-4cc2-aab3-bb7c67f19c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## permutation\n",
    "\n",
    "input_files = []\n",
    "for bandwidth in range(125, 2376, 125):\n",
    "    input_files.append(save_dir + '\\\\' f'shap_values_bw{bandwidth}_global.csv')\n",
    "\n",
    "opt_bandwidth = OptimizedBandwidth(X, y, input_files, shap_save_dir=save_dir)\n",
    "best_combination = opt_bandwidth.optimize_bandwidths()\n",
    "\n",
    "bst_gwxgb = best_combination['bst_shap_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605833b-8e93-42b2-88ea-e84ff7c2a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LtoG\n",
    "\n",
    "gw_shap_values = bst_gwxgb[['shap_0', 'shap_1', 'shap_2','shap_3', 'shap_4']]\n",
    "final_shap_values = gw_shap_values.copy()\n",
    "model_choice = {}\n",
    "shap_contributions = {}\n",
    "\n",
    "y_pred_current = np.sum(final_shap_values.values, axis=1) + np.mean(y)\n",
    "best_rmse = np.sqrt(mean_squared_error(y, y_pred_current))\n",
    "\n",
    "print(f\"Original RMSE: {best_rmse:.6f}\")\n",
    "\n",
    "for i in range(5):\n",
    "    shap_names = [f'shap_{j}' for j in range(X.shape[1])]\n",
    "    shap_names.pop(i)\n",
    "    y_pred_other = np.sum(final_shap_values[shap_names], axis=1) + np.mean(y)\n",
    "    y_pred_other = np.array(y_pred_other).reshape(-1, 1)\n",
    "    y_leave = y - y_pred_other\n",
    "    X_leave = X[:, i]\n",
    "\n",
    "    xgb_trainer = XGBoostTrainer_1(n_splits=5, random_state=42, n_jobs=20)\n",
    "    final_model, oof_preds, oof_rmse, oof_r2, oof_shap = xgb_trainer.calcu_oof_and_shap(X_leave, y_leave, tune=True, max_evals=50)\n",
    "\n",
    "    temp_shap_values = final_shap_values.copy()\n",
    "    temp_shap_values[f'shap_{i}'] = oof_preds\n",
    "    y_pred_new = np.sum(temp_shap_values.values, axis=1) + np.mean(y)\n",
    "    rmse_new = np.sqrt(mean_squared_error(y, y_pred_new))\n",
    "    r2_new = r2_score(y, y_pred_new)\n",
    "\n",
    "    print(f'\\nthe {i}_th var')\n",
    "    print(\"--- OOF Performance Metrics ---\")\n",
    "    print(f\"Current best RMSE: {best_rmse:.6f}\")\n",
    "    print(f\"New candidate RMSE: {rmse_new:.6f}\")\n",
    "\n",
    "    var_name = f'shap_{i}'\n",
    "    if rmse_new < best_rmse:\n",
    "        print(f'the best model for {i}_th var is xgb')\n",
    "        final_shap_values[var_name] = oof_preds  \n",
    "        model_choice[var_name] = 'xgb'\n",
    "        shap_contributions[var_name] = oof_preds\n",
    "        best_rmse = rmse_new  \n",
    "        y_pred_current = y_pred_new \n",
    "    else:\n",
    "        print(f'the best model for {i}_th var is geo')\n",
    "        model_choice[var_name] = 'geo'\n",
    "        shap_contributions[var_name] = final_shap_values[var_name].values\n",
    "\n",
    "print(\"\\nfinal model choice:\", model_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ee057-45a7-46b9-a17c-078be0894334",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185409d8-cefe-4897-9dba-16e6b8da5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_learner_types = list(model_choice.values())\n",
    "\n",
    "k_ranges_for_selection = [(125, 2376, 125), (125, 2376, 125), (125, 2376, 125), (125, 2376, 125), (125, 2376, 125)]\n",
    "\n",
    "col_names = [f'shap_{i}' for i in range(5)]\n",
    "initial_results = pd.DataFrame({\n",
    "    col: np.array(shap_contributions[col]).flatten()\n",
    "    for col in shap_contributions\n",
    "})\n",
    "\n",
    "shap_names = [f'shap_{j}' for j in range(X.shape[1])]\n",
    "ini_component_preds = np.array(initial_results[shap_names])\n",
    "\n",
    "m_gwxgb = M_GXGB(\n",
    "    data=X,                                                                                                                                                                                                                                                                            \n",
    "    target=y, \n",
    "    locations=coords,\n",
    "    selected_learner_types=selected_learner_types, \n",
    "    k_range=k_ranges_for_selection,\n",
    "    convergence_tol_percent=1,\n",
    "    n_jobs=20,\n",
    "    init_component_predictions=ini_component_preds\n",
    "    )\n",
    "\n",
    "m_gwxgb.fit()\n",
    "\n",
    "# Predict using the fitted M-GWXGB\n",
    "y_hat_mgwxgb = np.sum(m_gwxgb.component_predictions_, axis = 1) + np.mean(y)\n",
    "mgwxgb_global_shap = m_gwxgb.component_predictions_\n",
    "\n",
    "print(m_gwxgb.optimal_bandwidths_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113dae6-821f-4306-b536-5ffbf7de7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgwxgb_local = pd.DataFrame(gam_gb.local_prediction_df)\n",
    "mgwxgb_local.columns = ['shap_0', 'shap_1', 'index_2', 'shap_2', 'index_3', 'shap_3', 'index_4', 'shap_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0267648",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b98b6a-88c9-431b-9c6d-b6d826a56392",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgwxgb_rmse = np.sqrt(mean_squared_error(y.ravel(), y_hat_mgwxgb))\n",
    "mgwxgb_r2 = adjusted_r2_score(y.ravel(), y_hat_mgwxgb, 5)\n",
    "\n",
    "print(f\"RMSE: {mgwxgb_rmse:.4f}\")\n",
    "print(f\"Adj_R2: {mgwxgb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75cac2",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1579bda",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa1894-7976-4424-b089-6d23f14b820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 0.5, -0.5, -0.5, 2]\n",
    "locs_Y = [-3.2, -3.2, -4, -3, -0.9]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                mgwxgb_global_shap[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(mgwxgb_global_shap[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['M-GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwxgb_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148722bf-8e86-44b1-8872-4125f857902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local\n",
    "\n",
    "locs_X = [0.5, 0.5, 0.5, -0.5, 2]\n",
    "locs_Y = [-3.2, -3.2, -4, -2, -0.7]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper left', 'upper left']\n",
    "\n",
    "bws_mgwxgb = [2500, 2500, 15, 30, 406]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    if i in range(2, 5):\n",
    "            \n",
    "        vmin = bws_mgwxgb[i] * 1\n",
    "        vmax = bws_mgwxgb[i] * (1+1)\n",
    "        \n",
    "        nearest_indices = mgwxgb_local[vmin:vmax].loc[:, f'index_{i}']\n",
    "        nearest_indices_1 = nearest_indices.astype(int)\n",
    "        point_1_shap = mgwxgb_local[vmin:vmax].loc[:, f'shap_{i}']\n",
    "        point_1_x3 = X[nearest_indices_1, i]\n",
    "        f = fs[[nearest_indices_1], i].reshape(-1)\n",
    "\n",
    "        plt.scatter(point_1_x3, \n",
    "                    point_1_shap,\n",
    "                    c = 'none',\n",
    "                    edgecolors = 'green',\n",
    "                    alpha=0.6, \n",
    "                    s = 18)\n",
    "\n",
    "        plt.scatter(point_1_x3, \n",
    "                   f,\n",
    "                   edgecolors = 'k',\n",
    "                   alpha=0.6, \n",
    "                   s = 3)\n",
    "\n",
    "        plt.legend(['M-GWXGB curve', 'Actual curve'])\n",
    "\n",
    "        r2 = r2_score(point_1_shap, f)\n",
    "        plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "        plt.legend(['M-GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "        plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "        plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "    else:\n",
    "        plt.scatter(X[:, i], \n",
    "                    mgwxgb_global[f'f{i+1}_hat'],\n",
    "                    c = 'none',\n",
    "                    edgecolors = 'green',\n",
    "                    alpha=0.6, \n",
    "                    s = 18)\n",
    "\n",
    "        plt.scatter(X[:, i], \n",
    "                    fs[:, i], \n",
    "                    c = 'k', \n",
    "                    s = 3, \n",
    "                    alpha = 0.7)\n",
    "\n",
    "        r2 = r2_score(mgwxgb_global[f'f{i+1}_hat'], fs[:, i])\n",
    "        plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "        plt.legend(['M-GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "        plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "        plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "    \n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwxgb_X{i+1}_nl_local_1.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52658c9-8b0c-4689-ba29-9c4219a8fad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a2b1ebe-ddd9-4294-a26a-977f593df708",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5753471-9595-44f6-8ee9-465aa1654a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0, -3, -2.25, -3]\n",
    "vmaxs = [2.2, 3, 3, 2.25, 0.44]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(moving_wind(mgwxgb_global_shap[:, i], X[:, i]), fr'M-GWXGB: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = moving_wind(mgwxgb_global_shap[:, i], X[:, i]).reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwxgb_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0457c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44b57916",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7ec96",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7347a8a-1ebe-431a-a78d-98d2ee3166b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import kneighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e3d560-a708-4026-adcf-526c9c3f5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GCNTrainer:\n",
    "    def __init__(self, input_dim, n_splits=5, random_state=42):\n",
    "        self.input_dim = input_dim\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.best_params = None\n",
    "        self.best_avg_rmse = float('inf')\n",
    "\n",
    "        self.cv_scores = []\n",
    "        self.oof_predictions = None \n",
    "        self.oof_shap_values = None\n",
    "        self.oof_rmse = None\n",
    "        self.oof_r2 = None\n",
    "\n",
    "        self.X_scaler = None \n",
    "        self.y_scaler = None\n",
    "\n",
    "    def _train_fold(self, data, train_mask, val_mask, params):\n",
    "        \"\"\"Trains and evaluates the model for a single fold using specific parameters.\"\"\"\n",
    "        hidden_dim = int(params['hidden_dim'])\n",
    "        lr = params['lr']\n",
    "        num_epochs = int(params['num_epochs'])\n",
    "        dropout_rate = params['dropout_rate']\n",
    "        weight_decay = params['weight_decay']\n",
    "\n",
    "        model = GCNModel(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=1,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        criterion = nn.MSELoss() \n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)[train_mask]\n",
    "            loss = criterion(out, data.y[train_mask].view(-1, 1)) # Ensure target is 2D\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out_scaled = model(data)[val_mask].cpu().numpy()\n",
    "\n",
    "            y_val_scaled_np = data.y[val_mask].cpu().numpy().reshape(-1, 1) \n",
    "\n",
    "            val_out_original = self.y_scaler.inverse_transform(val_out_scaled)\n",
    "            y_val_original = self.y_scaler.inverse_transform(y_val_scaled_np)\n",
    "\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val_original, val_out_original))\n",
    "\n",
    "        return model, val_rmse, val_out_scaled\n",
    "\n",
    "    def _run_cv_for_objective(self, data_for_trial, params):\n",
    "        \"\"\"Runs K-Fold CV for a specific set of hyperparameters and graph structure.\"\"\"\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        fold_rmses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(data_for_trial.x.shape[0]))):\n",
    "            train_mask = torch.zeros(data_for_trial.x.shape[0], dtype=torch.bool)\n",
    "            val_mask = torch.zeros(data_for_trial.x.shape[0], dtype=torch.bool)\n",
    "            train_mask[train_idx] = True\n",
    "            val_mask[val_idx] = True\n",
    "\n",
    "            try:\n",
    "                 _, fold_rmse, _ = self._train_fold(data_for_trial, train_mask, val_mask, params)\n",
    "                 fold_rmses.append(fold_rmse)\n",
    "            except Exception as e:\n",
    "                 print(f\"Error training fold {fold+1} with params {params}: {e}\")\n",
    "                 return float('inf')\n",
    "\n",
    "        if not fold_rmses:\n",
    "            return float('inf')\n",
    "\n",
    "        avg_rmse = np.mean(fold_rmses)\n",
    "        return avg_rmse\n",
    "\n",
    "    def objective(self, params, X_tensor_scaled, y_tensor, coords, X_scaler, y_scaler):\n",
    "        \"\"\"Objective function for Hyperopt Bayesian Optimization.\"\"\"\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "        n_neighbors = int(params['n_neighbors'])\n",
    "        try:\n",
    "            graph = kneighbors_graph(coords, n_neighbors=n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "            edge_index = torch.tensor(np.array(graph.nonzero()), dtype=torch.long).contiguous() \n",
    "            data_for_trial = Data(x=X_tensor_scaled, edge_index=edge_index, y=y_tensor)\n",
    "        \n",
    "        except Exception as e:\n",
    "             print(f\"Error building graph with n_neighbors={n_neighbors}: {e}\")\n",
    "             return {'loss': float('inf'), 'status': STATUS_OK}\n",
    "\n",
    "        avg_cv_rmse = self._run_cv_for_objective(data_for_trial, params)\n",
    "\n",
    "        return {'loss': avg_cv_rmse, 'status': STATUS_OK}\n",
    "\n",
    "    def bayes_optimize(self, X_tensor_scaled, y_tensor, coords, X_scaler, y_scaler, search_space, max_evals=50):\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "        trials = Trials()\n",
    "\n",
    "        best = fmin(\n",
    "            fn=lambda params: self.objective(params, X_tensor_scaled, y_tensor, coords, X_scaler, y_scaler),\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(self.random_state)\n",
    "        )\n",
    "\n",
    "        self.best_params = {\n",
    "            'hidden_dim': int(best['hidden_dim']),\n",
    "            'lr': best['lr'],\n",
    "            'num_epochs': int(best['num_epochs']),\n",
    "            'dropout_rate': best['dropout_rate'],\n",
    "            'weight_decay': best['weight_decay'],\n",
    "            'n_neighbors': int(best['n_neighbors'])\n",
    "        }\n",
    "\n",
    "        print(\"\\nRe-evaluating best parameters to get final CV RMSE...\")\n",
    "        best_n_neighbors = int(self.best_params['n_neighbors'])\n",
    "        graph_best = kneighbors_graph(coords, n_neighbors=best_n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "        edge_index_best = torch.tensor(np.array(graph_best.nonzero()), dtype=torch.long).contiguous()\n",
    "        data_best_graph = Data(x=X_tensor_scaled, edge_index=edge_index_best, y=y_tensor)\n",
    "\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "        self.best_avg_rmse = self._run_cv_for_objective(data_best_graph, self.best_params)\n",
    "\n",
    "        print(\"\\nBayesian Optimization complete.\")\n",
    "        print(f\"Best Hyperparameters found: {self.best_params}\")\n",
    "        print(f\"Best Average CV RMSE from Re-evaluation: {self.best_avg_rmse:.4f}\")\n",
    "        return self.best_params, self.best_avg_rmse\n",
    "\n",
    "    def predict_for_shap(self, x_np_batch, model, X_scaler, y_scaler, n_neighbors):\n",
    "\n",
    "        model.eval()\n",
    "        x_np_batch = x_np_batch.astype(np.float32)\n",
    "\n",
    "        try:\n",
    "             coords_batch = x_np_batch[:, :2]\n",
    "             if coords_batch.shape[0] <= n_neighbors:\n",
    "                return np.full(x_np_batch.shape[0], np.nan)\n",
    "\n",
    "             graph = kneighbors_graph(coords_batch, n_neighbors=n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "             edge_index_batch = torch.tensor(np.array(graph.nonzero()), dtype=torch.long).contiguous() # Ensure contiguous\n",
    "        except Exception as e:\n",
    "             print(f\"Unexpected error building graph for SHAP with n_neighbors={n_neighbors}, batch shape {x_np_batch.shape}: {e}\")\n",
    "             return np.full(x_np_batch.shape[0], np.nan)\n",
    "\n",
    "        x_tensor_scaled = torch.tensor(X_scaler.transform(x_np_batch), dtype=torch.float32)\n",
    "\n",
    "        new_data_batch = Data(x=x_tensor_scaled, edge_index=edge_index_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions_scaled = model(new_data_batch).detach().cpu().numpy() # Move to CPU\n",
    "\n",
    "            predictions_original = y_scaler.inverse_transform(predictions_scaled)\n",
    "\n",
    "        return predictions_original.flatten()\n",
    "\n",
    "    def calculate_oof_and_shap(self, X_tensor_scaled, y_tensor, coords, X_original_np, y_original_np, X_scaler, y_scaler, feature_names):\n",
    "\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"Best parameters not set. Run bayes_optimize first.\")\n",
    "\n",
    "        # Store scalers\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "        best_n_neighbors = int(self.best_params['n_neighbors'])\n",
    "        print(f\"\\nBuilding final graph for OOF run with best n_neighbors: {best_n_neighbors}\")\n",
    "        try:\n",
    "             graph = kneighbors_graph(coords, n_neighbors=best_n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "             edge_index_final = torch.tensor(np.array(graph.nonzero()), dtype=torch.long).contiguous() # Ensure contiguous\n",
    "             data_final = Data(x=X_tensor_scaled, edge_index=edge_index_final, y=y_tensor)\n",
    "             print(f\"Final graph built with {edge_index_final.shape[1]} edges.\")\n",
    "        except Exception as e:\n",
    "            print(f\"FATAL ERROR: Could not build final graph with n_neighbors={best_n_neighbors}: {e}\")\n",
    "            self.oof_rmse, self.oof_r2 = np.nan, np.nan\n",
    "            return np.full(X_original_np.shape[0], np.nan), np.full(X_original_np.shape, np.nan), self.oof_rmse, self.oof_r2, np.zeros(X_original_np.shape[0], dtype=bool)\n",
    "\n",
    "        print(f\"\\nStarting {self.n_splits}-Fold CV for OOF predictions and SHAP values using best params...\")\n",
    "\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "\n",
    "        self.oof_predictions = np.zeros(X_original_np.shape[0])\n",
    "        self.oof_shap_values = np.zeros(X_original_np.shape)\n",
    "        self.cv_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(data_final.x.shape[0]))):\n",
    "            print(f\"\\n--- Processing Fold {fold+1}/{self.n_splits} ---\")\n",
    "\n",
    "            train_mask = torch.zeros(data_final.x.shape[0], dtype=torch.bool)\n",
    "            val_mask = torch.zeros(data_final.x.shape[0], dtype=torch.bool)\n",
    "            train_mask[train_idx] = True\n",
    "            val_mask[val_idx] = True\n",
    "\n",
    "            fold_model, fold_val_rmse, val_out_scaled = self._train_fold(data_final, train_mask, val_mask, self.best_params)\n",
    "            self.cv_scores.append(fold_val_rmse)\n",
    "            print(f\"Fold {fold+1} Validation RMSE: {fold_val_rmse:.4f}\")\n",
    "\n",
    "            val_preds_original = self.y_scaler.inverse_transform(val_out_scaled)\n",
    "            self.oof_predictions[val_idx] = val_preds_original.flatten() # Ensure 1D\n",
    "\n",
    "            X_val_fold_np = X_original_np[val_idx] \n",
    "\n",
    "            if len(X_val_fold_np) > 0:\n",
    "                # Instantiate SHAP Explainer\n",
    "                print(f\"Calculating SHAP values for {len(val_idx)} validation nodes in Fold {fold+1} using best n_neighbors={best_n_neighbors}...\")\n",
    "                try:\n",
    "                     explainer = shap.Explainer(\n",
    "                         lambda x_batch: self.predict_for_shap(x_batch, fold_model, self.X_scaler, self.y_scaler, best_n_neighbors),\n",
    "                         X_original_np[train_idx], \n",
    "                         feature_names=feature_names \n",
    "                     )\n",
    "\n",
    "                     shap_values_fold = explainer(X_val_fold_np).values\n",
    "                     print(f\"Finished SHAP calculation for Fold {fold+1}.\")\n",
    "\n",
    "                     self.oof_shap_values[val_idx, :] = shap_values_fold\n",
    "\n",
    "                except Exception as e:\n",
    "                     print(f\"SHAP calculation failed for Fold {fold+1}: {e}\")\n",
    "                     print(\"Storing NaNs for SHAP values in this fold.\")\n",
    "                     self.oof_shap_values[val_idx, :] = np.full_like(self.oof_shap_values[val_idx, :], np.nan)\n",
    "\n",
    "            else:\n",
    "                 print(f\"  Fold {fold+1} validation set is empty. Skipping SHAP calculation.\")\n",
    "\n",
    "        print(\"\\n5-Fold CV and SHAP calculation complete.\")\n",
    "\n",
    "        valid_nodes_for_oof = ~np.isnan(self.oof_predictions)\n",
    "        shap_row_has_nan = np.isnan(self.oof_shap_values).any(axis=1)\n",
    "        valid_nodes_for_oof = valid_nodes_for_oof & (~shap_row_has_nan)\n",
    "\n",
    "\n",
    "        if valid_nodes_for_oof.sum() > 0:\n",
    "             y_valid = y_original_np[valid_nodes_for_oof]\n",
    "             oof_preds_valid = self.oof_predictions[valid_nodes_for_oof]\n",
    "             oof_shap_valid = self.oof_shap_values[valid_nodes_for_oof]\n",
    "             X_combined_valid = X_original_np[valid_nodes_for_oof]\n",
    "\n",
    "             # Calculate overall OOF metrics on valid nodes\n",
    "             self.oof_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds_valid))\n",
    "             self.oof_r2 = r2_score(y_valid, oof_preds_valid)\n",
    "\n",
    "             print(f\"\\n--- Overall OOF Results (on {valid_nodes_for_oof.sum()} valid nodes) ---\")\n",
    "             print(f\"Overall OOF RMSE: {self.oof_rmse:.4f}\")\n",
    "             print(f\"Overall OOF R2: {self.oof_r2:.4f}\")\n",
    "             print(f\"Average Fold Validation RMSE: {np.mean(self.cv_scores):.4f} (Std: {np.std(self.cv_scores):.4f})\")\n",
    "             return self.oof_predictions, self.oof_shap_values, self.oof_rmse, self.oof_r2, valid_nodes_for_oof, X_combined_valid\n",
    "        else:\n",
    "            print(\"No valid OOF predictions or SHAP values were computed across folds.\")\n",
    "            self.oof_rmse, self.oof_r2 = np.nan, np.nan\n",
    "            return self.oof_predictions, self.oof_shap_values, self.oof_rmse, self.oof_r2, valid_nodes_for_oof, None # Return None for X_combined_valid if no valid nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ad52c-54b3-41a6-85f5-0dfaccd57f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (fit on full X)\n",
    "\n",
    "feature_names = [f'X{i+1}' for i in range(X.shape[1])]\n",
    "X_combined = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_combined_standardized = X_scaler.fit_transform(X)\n",
    "\n",
    "# Standardize target separately\n",
    "y_scaler = StandardScaler()\n",
    "y_standardized = y_scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_tensor_scaled = torch.tensor(X_combined_standardized, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_standardized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38856767-3b8e-45a7-b205-9afe2bd2f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'hidden_dim': hp.quniform('hidden_dim', 16, 128, 1), \n",
    "    'lr': hp.loguniform('lr', np.log(0.00005), np.log(0.01)),\n",
    "    'num_epochs': hp.quniform('num_epochs', 100, 600, 1), \n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.6),\n",
    "    'weight_decay': hp.loguniform('weight_decay', np.log(1e-5), np.log(1e-3)),\n",
    "    'n_neighbors': hp.quniform('n_neighbors', 10, 40, 1) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af19424-0e22-480f-90af-abf4f15d61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInstantiating GCN Trainer...\")\n",
    "gcn_trainer = GCNTrainer(\n",
    "    input_dim=X_combined_standardized.shape[1],\n",
    "    n_splits=5,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Bayesian Optimization...\")\n",
    "start_time_bo = time.time()\n",
    "max_optimization_evals = 50 \n",
    "\n",
    "best_params, best_avg_rmse_opt = gcn_trainer.bayes_optimize(\n",
    "    X_tensor_scaled, y_tensor, coords, X_scaler, y_scaler, search_space, max_evals=max_optimization_evals\n",
    ")\n",
    "end_time_bo = time.time()\n",
    "print(f\"Bayesian Optimization ({max_optimization_evals} evals) took {end_time_bo - start_time_bo:.2f} seconds.\")\n",
    "\n",
    "start_time_oof_shap = time.time()\n",
    "oof_predictions, oof_shap_values, oof_rmse, oof_r2, valid_nodes_for_oof, X_combined_valid = gcn_trainer.calculate_oof_and_shap(\n",
    "    X_tensor_scaled, y_tensor, coords, X, y, X_scaler, y_scaler, feature_names\n",
    ")\n",
    "end_time_oof_shap = time.time()\n",
    "print(f\"OOF prediction and SHAP calculation took {end_time_oof_shap - start_time_oof_shap:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca3b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11cdabd",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602cfec-282f-44c3-bed5-dced3483ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: \", oof_rmse)\n",
    "print(\"adj_R2: \", adjusted_r2_score(oof_predictions, y, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd62b0c",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87524f1d",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec95cb0-794a-481b-920d-d487d3cfba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global\n",
    "\n",
    "locs_X = [0.5, 0.5, -0.5, -0.5, 2.2]\n",
    "locs_Y = [-6.5, -6.5, -4.2, -3.2, -1]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                oof_shap_values[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(oof_shap_values[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GCN curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gcn_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d699ec-e720-47a1-9d95-d9ab079ac428",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local\n",
    "\n",
    "x_test = np.random.uniform(-1.5, 1.5, 2500)\n",
    "f_test = - x_test ** 3\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    b = oof_shap_values[:, i][2448] / X[:, i][2448]\n",
    "    plt.scatter(x_test, \n",
    "                b*x_test,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(x_test, \n",
    "                f_test, \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(b*x_test, f_test)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GCN curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gcn_X{i+1}_nl_local_1.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553aec5",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73b806-f30d-47b4-9e2f-b1bd5f7c369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0, -3, -2.25, -3]\n",
    "vmaxs = [2.2, 3, 3, 2.25, 0.44]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(moving_wind(oof_shap_values[:, i], X[:, i]), fr'GCN: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = moving_wind(oof_shap_values[:, i], X[:, i]).reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gcn_X{i+1}_s.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46f393",
   "metadata": {},
   "source": [
    "# GGP-GAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d94ca",
   "metadata": {},
   "source": [
    "## GGP_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d3e5e-fb8b-4758-aca6-2f3981de18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp_results = pd.read_csv(save_dir + '\\\\' + r'ggp_gam_svc_all_location_results.csv') ## generated by R code\n",
    "\n",
    "ggp_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d93c01",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a629d-7211-4bd4-93e0-62d74fe52bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(ggp_results['predicted_y_svc_all']).reshape(-1, 1)\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print(\"adj_R2: \", adjusted_r2_score(y, result.predy, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454529f7",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa132a-eae4-40ed-919c-9bf9adb21ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.array(ggp_results[['estimated_beta_X1', 'estimated_beta_X2', 'estimated_beta_X3', 'estimated_beta_X4', 'estimated_beta_X5']]).reshape(2500, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df282f28-183d-4173-acb2-b1ffb914c73f",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00400af5-f6e3-493f-8a09-7f6bec621f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 0.5, -0.5, -0.5, 2]\n",
    "locs_Y = [-3.2, -3.2, -4, -3, -0.6]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                betas[:, i] * X[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(betas[:, i] * X[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GGP-GAM curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'ggp_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e2b7f-296d-4d9d-87a4-075010bd25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local relationships\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                betas[:, i] * X[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(betas[:, i] * X[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GGP-GAM curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'ggp_X{i+1}_nl_local.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d6f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b9266c",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737e9e6-edd1-469a-84b4-930525873b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0, -3, -2.25, -3]\n",
    "vmaxs = [2.2, 3, 3, 2.25, 0.44]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(betas[:, i], fr'GGP-GAM: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = betas[:, i].reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'ggp_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eafe97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66fef420",
   "metadata": {},
   "source": [
    "# S-GWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33723eb0-dea5-480a-986f-35c5434c7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgwr_results = pd.read_csv(save_dir + '\\\\' + r'S_GWR_listwise.csv')\n",
    "sgwr_results[' est_x1'] = 1.988711  ## extract from the \"txt\" file generated by the GWR 4.0 Software\n",
    "sgwr_results[' est_x2'] = 1.304958\n",
    "sgwr_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05caf4b3",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d11e4c-6de0-4095-a5ba-37cc3ab20a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(sgwr_results[' yhat']).reshape(-1, 1)\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print(\"adj_R2: \", adjusted_r2_score(y, y_pred, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f1a9a-b1f0-4e10-a880-a9c50576c585",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e4621-be14-4977-ad16-498e6033a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.array(sgwr_results[[' est_x1', ' est_x2', ' est_x3', ' est_x4', ' est_x5']]).reshape(2500, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccafdb1",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf3b6f-5ebe-4267-9c6d-cfa7aa982698",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 0.5, -0.5, -0.5, 2]\n",
    "locs_Y = [-3.2, -3.2, -4, -3, -0.6]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                betas[:, i] * X[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(params[:, i] * X[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['S-GWR curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'sgwr_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd52f1-0ddf-48c2-98f9-d4c9fd618769",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local relationships\n",
    "\n",
    "locs_X = [0.5, 0.5, -0.5, 0.5, 1]\n",
    "locs_Y = [-3.2, -3.2, -2, -2.8, -0.7]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper left', 'upper left']\n",
    "\n",
    "n_neighbors = 124 \n",
    "nn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', metric='euclidean')\n",
    "nn.fit(coords)\n",
    "distances, selected_indices_list = nn.kneighbors(coords)\n",
    "\n",
    "nearest_indices = selected_indices_list[52]\n",
    "\n",
    "for i in range(5):\n",
    "        \n",
    "    b = betas[:, i][52]\n",
    "    f = fs[[nearest_indices], i].reshape(-1)\n",
    "    point_1_x3 = X[nearest_indices, i]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "                b*point_1_x3,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "               f,\n",
    "               edgecolors = 'k',\n",
    "               alpha=0.6, \n",
    "               s = 3)\n",
    "\n",
    "    plt.legend(['S-GWR curve', 'Actual curve'])\n",
    "\n",
    "    r2 = r2_score(b*point_1_x3, f)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "    \n",
    "    plt.legend(['S-GWR curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'sgwr_X{i+1}_nl_local.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee68af8",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2486f-789e-4b62-9b31-9750487dd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0, -3, -2.25, -3]\n",
    "vmaxs = [2.2, 3, 3, 2.25, 0.44]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(betas[:, i], fr'S-GWR: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = betas[:, i].reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'sgwr_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b22da84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0391e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309.9px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
