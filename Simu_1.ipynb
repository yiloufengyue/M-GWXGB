{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad058d6-a49e-47ee-a51c-4f7b2f2bc401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from joblib import Parallel, delayed\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from itertools import product\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b84a488-a3fa-4df6-98c0-a95ffdd5f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from M_GWXGB_1 import GeoWeightedXGBoostTrainer, GeoWeightedXGBoostInterpreter, GeoWeightedXGBoostPredictor, M_GWXGB_Initial, OptimizedBandwidth, M_GXGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d8a7fa4c-6c8b-493e-8d45-13647be23b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from M_GWXGB_cluster import GeoWeightedXGBoostTrainer_1, GeoWeightedXGBoostInterpreter, GeoWeightedXGBoostPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95d0c35-76ba-458f-a607-fa9100e602ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4706cc-5d35-4aad-ac2e-792a7072de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd45da43-bfd8-48ec-b593-12a3b75a2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "126d1e67-b279-47a9-a03f-d2000b458436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483dde73-9d7c-4f61-8baa-e28598617110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 25\n",
    "mpl.rcParams['axes.unicode_minus'] = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1f6bb-acae-4e9d-8cf9-0f66281f299d",
   "metadata": {},
   "source": [
    "# Function defination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101ca58-5136-4716-a051-125cd73274ec",
   "metadata": {},
   "source": [
    "## Adj_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab42b0ba-b351-40de-935a-6efc67e11c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r2_score(y_true, y_pred, n_features):\n",
    "    n_samples = len(y_true)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    if n_samples <= n_features + 1:\n",
    "        raise ValueError(\" \")\n",
    "    \n",
    "    adjusted_r2 = 1 - (1 - r2) * (n_samples - 1) / (n_samples - n_features - 1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d11025",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b71de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50\n",
    "def moving_wind(f1_est,X1,w=2):\n",
    "    mat = np.zeros((size,size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if i == 0 and j == 0:\n",
    "                top = f1_est.reshape(size,size)[0:w,0:w]\n",
    "                bot = X1.reshape(size,size)[0:w,0:w]\n",
    "                \n",
    "            if i == 0 and j > 0:\n",
    "                top = f1_est.reshape(size,size)[0:i+w,j-1:j+w]\n",
    "                bot = X1.reshape(size,size)[0:i+w,j-1:j+w]\n",
    "                \n",
    "            if j == 0 and i > 0:\n",
    "                top = f1_est.reshape(size,size)[i-1:i+w,0:j+w]\n",
    "                bot = X1.reshape(size,size)[i-1:i+w,0:j+w]\n",
    "                \n",
    "            if i > 0 and j > 0 : \n",
    "                top = f1_est.reshape(size,size)[i-1:i+w,j-1:j+w]\n",
    "                bot = X1.reshape(size,size)[i-1:i+w,j-1:j+w]\n",
    "            \n",
    "            m = np.linalg.lstsq(bot.reshape(-1,1), top.reshape(-1,1), rcond=None)[0][0,0]\n",
    "            if m > size:\n",
    "                print(i,j)\n",
    "            mat[i,j] = m\n",
    "            \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d77835-45d5-4b0a-87f1-a16ab2e95639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.matplotlib import Inferno_3\n",
    "\n",
    "def plot_1(b,title,vmin=None,vmax=None):\n",
    "    size = 50\n",
    "    plt.figure(figsize=(6, 4), dpi=300)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(b.reshape(size,size),vmin=vmin, vmax=vmax, cmap=Inferno_3.mpl_colormap)\n",
    "    plt.title(title,fontsize=25)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9397b-1d7b-4ee7-968f-1e88ef095622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08f0d9d0-4aef-4e26-b272-1c2bde86f75c",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfda6a2d-63bd-4b25-acf5-58a8d632b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50\n",
    "\n",
    "X1 = np.random.uniform(-1.5, 1.5, size*size)\n",
    "X2 = np.random.uniform(0, 3, size*size)\n",
    "X3 = np.random.uniform(-1.5, 1.5, size*size)\n",
    "X4 = np.random.uniform(-1.5, 1.5, size*size)\n",
    "X = np.vstack([X1, X2, X3, X4]).T\n",
    "\n",
    "u = np.array([np.linspace(0, size-1, num=size)]*size).reshape(-1)\n",
    "v = np.array([np.linspace(0, size-1, num=size)]*size).T.reshape(-1)\n",
    "coords = list(zip(u, v))\n",
    "\n",
    "f0 = 2\n",
    "f1 = 2 * X1\n",
    "f2 = np.log(X2 / 2) * X2\n",
    "f3 = X3**3\n",
    "\n",
    "f4 = np.zeros_like(X4)\n",
    "mask_left = u < (size / 2)\n",
    "mask_right = ~mask_left\n",
    "\n",
    "f4[mask_left] = X4[mask_left] ** 3\n",
    "f4[mask_right] = -X4[mask_right] ** 3\n",
    "\n",
    "err = np.random.uniform(-1.5,1.5,size*size)\n",
    "fs = np.vstack([f1, f2, f3, f4]).T\n",
    "y = (f0 + f1 + f2 + f3 + f4 + err).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eef30442-a02d-4e58-901c-fa05e05c5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'E:\\PaperCode\\S-MGXGB\\SimuResults_S2_1\\data_1.csv')\n",
    "y = np.array(data['y']).reshape(-1, 1)\n",
    "X = np.array(data[['x1', 'x2', 'x3', 'x4']]).reshape(2500, 4)\n",
    "coords = np.array(data[['lng', 'lat']]).reshape(2500, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650d082-d0b8-48ff-afcb-1890d14656ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c1ec6-4b2e-4147-9dd8-46cfba428c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input the figure saving path\n",
    "\n",
    "save_path= r'...\\\\Simu_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ef360-e1c3-47bc-976b-1562964df908",
   "metadata": {},
   "outputs": [],
   "source": [
    "## actual parameter surfaces\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(fs[:, i] / X[:, i], fr'actual: $f_{i+1} $')\n",
    "    \n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'actual_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a56f9-302c-4baa-bc08-ad4834a17936",
   "metadata": {},
   "outputs": [],
   "source": [
    "## actual non-linear relationships\n",
    "\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    plt.ylabel(rf'$f_{i+1} X_{i+1} \\sim X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "    \n",
    "    plt.savefig(save_path + '\\\\' + rf'true_f{i+1}_nl.jpg',\n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b274a0-060a-4094-8743-14e17b3e5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "## actual non-linear relationships of f4\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "plt.scatter(X[:, 3], \n",
    "            fs[:, 3], \n",
    "            c = fs[:, 3],\n",
    "            cmap = Inferno_3.mpl_colormap, \n",
    "            s = 3, \n",
    "            alpha = 0.7)\n",
    "\n",
    "plt.ylabel(rf'$f_4 X_4 \\sim X_4$')\n",
    "plt.xlabel(fr'$\\mathrm{{X}}_4$')\n",
    "\n",
    "plt.savefig(save_path + '\\\\' + rf'true_f4_nl.jpg',\n",
    "            dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e42e34-921d-44f0-bf99-4ad040c98680",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "plt.scatter(X4[mask_right], \n",
    "            f4[mask_right], \n",
    "            c = f4[mask_right],\n",
    "            cmap = Inferno_3.mpl_colormap, \n",
    "            s = 3, \n",
    "            alpha = 0.7)\n",
    "\n",
    "plt.ylabel(rf'$f_4 X_4 \\sim X_4$')\n",
    "plt.xlabel(fr'$\\mathrm{{X}}_4$')\n",
    "\n",
    "plt.savefig(save_path + '\\\\' + rf'true_f4_nl_right.jpg',\n",
    "            dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd77e22-7840-40db-9942-b71fdd46d361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45c12248-0328-48ca-8ab8-464eeba4ddc7",
   "metadata": {},
   "source": [
    "# XGBoost model\n",
    "5 fold cross-validation is used to form a complete prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc120cd4-0bec-45a9-a38e-46e7117fd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostTrainer_1:\n",
    "    def __init__(self, n_splits=5, random_state=42, n_jobs=-1):\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.oof_predictions = None\n",
    "        self.cv_scores = []\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.best_iterations_per_fold = []\n",
    "        self.oof_shap_values = None\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def _train_fold(self, params, X, y, train_idx, val_idx, fold_num):\n",
    "\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        dtrain_fold = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "        dvalid_fold = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "\n",
    "        watchlist = [(dvalid_fold, 'eval')]\n",
    "\n",
    "        model = xgb.train(params,\n",
    "                         dtrain_fold,\n",
    "                         num_boost_round=1000,\n",
    "                         evals=watchlist,\n",
    "                         early_stopping_rounds=30,\n",
    "                         verbose_eval=False)\n",
    "\n",
    "        return {\n",
    "            'fold_num': fold_num,\n",
    "            'score': model.best_score,\n",
    "            'model': model,\n",
    "            'val_idx': val_idx\n",
    "        }\n",
    "\n",
    "    def objective(self, params, X, y):\n",
    "        params['max_depth'] = int(params['max_depth'])\n",
    "        params['min_child_weight'] = int(params['min_child_weight'])\n",
    "\n",
    "        param_use = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            **params\n",
    "        }\n",
    "\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        folds = list(kf.split(X, y))\n",
    "\n",
    "        results = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._train_fold)(\n",
    "                param_use, X, y, train_idx, val_idx, fold_num\n",
    "            )\n",
    "            for fold_num, (train_idx, val_idx) in enumerate(folds)\n",
    "        )\n",
    "\n",
    "        cv_scores = [res['score'] for res in results]\n",
    "        avg_cv_score = np.mean(cv_scores)\n",
    "        \n",
    "        return {'loss': avg_cv_score, 'status': STATUS_OK}\n",
    "\n",
    "    def _cv_fold(self, X, y, train_idx, val_idx, fold_num):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        dtrain_fold = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "        dvalid_fold = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "\n",
    "        watchlist = [(dtrain_fold, 'train'), (dvalid_fold, 'eval')]\n",
    "\n",
    "        fold_model = xgb.train(self.best_params,\n",
    "                             dtrain_fold,\n",
    "                             num_boost_round=2000,\n",
    "                             evals=watchlist,\n",
    "                             early_stopping_rounds=50,\n",
    "                             verbose_eval=100 if fold_num == 0 else False)\n",
    "\n",
    "        best_iteration = fold_model.best_iteration\n",
    "        fold_score = fold_model.best_score\n",
    "\n",
    "        oof_preds_fold = fold_model.predict(dvalid_fold, iteration_range=(0, best_iteration))\n",
    "        \n",
    "        fold_explainer = shap.TreeExplainer(fold_model)\n",
    "        fold_shap_value = fold_explainer.shap_values(dvalid_fold)\n",
    "\n",
    "        return {\n",
    "            'fold_num': fold_num,\n",
    "            'best_iteration': best_iteration,\n",
    "            'score': fold_score,\n",
    "            'val_idx': val_idx,\n",
    "            'oof_pred': oof_preds_fold,\n",
    "            'shap_values': fold_shap_value,\n",
    "            'model': fold_model\n",
    "        }\n",
    "\n",
    "    def calcu_oof_and_shap(self, X, y, tune=True, max_evals=50):\n",
    "        if y.ndim > 1 and y.shape[1] == 1:\n",
    "            y = y.ravel()\n",
    "            \n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "\n",
    "        if tune or self.best_params is None:\n",
    "            self.tune_params(X, y, max_evals=max_evals)\n",
    "        elif not tune and self.best_params is None:\n",
    "            raise ValueError(\"Cannot train without tuning if best_params are not already set.\")\n",
    "\n",
    "        print(f\"\\nStarting {self.n_splits}-Fold CV for OOF predictions (parallel)...\")\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        folds = list(kf.split(X, y))\n",
    "\n",
    "        self.oof_predictions = np.zeros(X.shape[0])\n",
    "        self.oof_shap_values = np.zeros(X.shape)\n",
    "        self.cv_scores = []\n",
    "        self.best_iterations_per_fold = []\n",
    "\n",
    "        results = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._cv_fold)(X, y, train_idx, val_idx, fold_num)\n",
    "            for fold_num, (train_idx, val_idx) in enumerate(folds)\n",
    "        )\n",
    "\n",
    "        for res in results:\n",
    "            self.best_iterations_per_fold.append(res['best_iteration'])\n",
    "            self.cv_scores.append(res['score'])\n",
    "            self.oof_predictions[res['val_idx']] = res['oof_pred']\n",
    "            self.oof_shap_values[res['val_idx']] = res['shap_values']\n",
    "\n",
    "        oof_rmse = np.sqrt(mean_squared_error(y, self.oof_predictions))\n",
    "        oof_r2 = adjusted_r2_score(y, self.oof_predictions, X.shape[1])\n",
    "        \n",
    "        print(\"\\n--- Training Final Model on Full Data ---\")\n",
    "        final_num_boost_round = int(np.median(self.best_iterations_per_fold))\n",
    "        dfull = xgb.DMatrix(X, label=y)\n",
    "\n",
    "        self.best_model = xgb.train(self.best_params,\n",
    "                                  dfull,\n",
    "                                  num_boost_round=final_num_boost_round,\n",
    "                                  verbose_eval=100)\n",
    "\n",
    "        print(\"Final model training complete.\")\n",
    "        return self.best_model, self.oof_predictions, oof_rmse, oof_r2, self.oof_shap_values\n",
    "\n",
    "    def tune_params(self, X, y, max_evals=50):\n",
    "        search_space = {\n",
    "            \"max_depth\": hp.quniform('max_depth', 3, 8, 1),\n",
    "            \"learning_rate\": hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "            \"subsample\": hp.uniform('subsample', 0.6, 1.0),\n",
    "            \"colsample_bytree\": hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "            \"min_child_weight\": hp.quniform('min_child_weight', 1, 6, 1),\n",
    "            \"gamma\": hp.uniform('gamma', 0, 0.5),\n",
    "            \"reg_alpha\": hp.loguniform('reg_alpha', np.log(0.001), np.log(1.0)),\n",
    "            \"reg_lambda\": hp.loguniform('reg_lambda', np.log(0.1), np.log(10.0)),\n",
    "        }\n",
    "\n",
    "        trials = Trials()\n",
    "        best = fmin(\n",
    "            fn=lambda params: self.objective(params, X, y),\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(self.random_state)\n",
    "        )\n",
    "\n",
    "        self.best_params = {\n",
    "            'max_depth': int(best['max_depth']),\n",
    "            'learning_rate': best['learning_rate'],\n",
    "            'subsample': best['subsample'],\n",
    "            'colsample_bytree': best['colsample_bytree'],\n",
    "            'min_child_weight': int(best['min_child_weight']),\n",
    "            'gamma': best['gamma'],\n",
    "            'reg_alpha': best['reg_alpha'],\n",
    "            'reg_lambda': best['reg_lambda'],\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        print(\"\\nBest parameters found:\")\n",
    "        print(self.best_params)\n",
    "        return self.best_params\n",
    "\n",
    "    def predict(self, X):\n",
    "        dmatrix = xgb.DMatrix(X)\n",
    "        return self.best_model.predict(dmatrix)\n",
    "\n",
    "    def compute_shap_values(self, X):\n",
    "        explainer = shap.TreeExplainer(self.best_model)\n",
    "        dmatrix = xgb.DMatrix(X)\n",
    "        return explainer.shap_values(dmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b6867",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b987b-8143-432c-9de4-30a63fb0da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X_1 = np.concatenate((X, coords), axis=1)\n",
    "xgb_trainer = XGBoostTrainer_1(n_splits=5, random_state=42, n_jobs=4)\n",
    "final_model, oof_preds, oof_rmse, oof_r2, oof_shap = xgb_trainer.calcu_oof_and_shap(X_1, y, tune=True, max_evals=50)\n",
    "\n",
    "print(f'rmse: {oof_rmse}')\n",
    "print(f'r2: {oof_r2}')\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f1422-dfb0-4911-93fc-5a3d8ca25e8a",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b914f98-d268-456c-89bd-4d354b64851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: \", oof_rmse)\n",
    "print(\"adj_R2: \", adjusted_r2_score(oof_predictions, y, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6e912",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e30d7b",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a86843-a814-4014-83f3-587620abff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 2.2, 0.5, -0.5]\n",
    "locs_Y = [-3.2, -0.9, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                oof_shap[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(oof_shap[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['XGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'xgb_X{i+1}_nl.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca8bce-30cc-40d2-a4b8-5b6ae6f3b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local\n",
    "\n",
    "x_test = np.random.uniform(-1.5, 1.5, 2500)\n",
    "f_test = -x_test ** 3\n",
    "\n",
    "point_id = 'your point id'\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    b = oof_shap[:, i][point_id] / X[:, i][point_id]\n",
    "    plt.scatter(x_test, \n",
    "                b*x_test,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(x_test, \n",
    "                f_test, \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(b*x_test, f_test)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['XGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'xgb_X{i+1}_nl_local_2448.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03e3da",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c805635-2ffc-4fa9-b6ee-b0f68131cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0.5, -3, -2.25]\n",
    "vmaxs = [2.2, 3, 3, 2.25]\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(moving_wind(oof_shap[:, i], X[:, i]), fr'XGB: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = moving_wind(oof_shap[:, i], X[:, i]).reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'xgb_X{i+1}_s.jpg', \n",
    "                dpi = 300)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42678efa",
   "metadata": {},
   "source": [
    "# GWXGB model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa1408",
   "metadata": {},
   "source": [
    "## train model\n",
    "\n",
    "obtain the best model from 19 bandwidth (using the geographic clustering approach for searching the best bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f8d0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_set(target, gwxgb_trainer):\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "    test_indices_list, test_predictions_list = gwxgb_trainer.test_indices_list, gwxgb_trainer.test_predictions_list\n",
    "    for i, (test_indices, y_pred_test) in enumerate(zip(test_indices_list, test_predictions_list)):\n",
    "            \n",
    "        y_test = target[test_indices]\n",
    "        mse_score = mean_squared_error(y_test, y_pred_test)\n",
    "        mse_scores.append(mse_score)\n",
    "        r2 = r2_score(y_test, y_pred_test)\n",
    "        r2_scores.append(r2)\n",
    "    return np.mean(mse_scores), np.mean(r2_scores) if mse_scores else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fa15a-f027-43d5-957b-c707239daf8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 寻找最优带宽\n",
    "\n",
    "k_range = (125, 275, 125)\n",
    "save_dir = r'your output path'\n",
    "\n",
    "gwxgb_trainer = GeoWeightedXGBoostTrainer(data=X,\n",
    "                                          target=y,\n",
    "                                          locations=coords,\n",
    "                                          n_jobs=8, \n",
    "                                          use_full_sample = True,\n",
    "                                          n_clusters=100)                          \n",
    "optimal_k = gwxgb_trainer.search_optimal_k_nearest(k_range)\n",
    "print(optimal_k)\n",
    "gwxgb_trainer.fit()\n",
    "\n",
    "local_y_hat, y_hat = gwxgb_trainer.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60d9b5a4-21d5-4f4b-aba7-8355056a9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_interpolator_fill(y_hat, coords, method='weighted', k=10, power=2):\n",
    "    \"\"\"\n",
    "    使用空间邻居的预测值填补缺失值\n",
    "    \n",
    "    参数：\n",
    "    - y_hat_df: pd.DataFrame，包含 'index' 和 'predy' 的模型预测结果（只有部分样本有）\n",
    "    - coords: ndarray[n_samples, 2]，所有样本点的坐标\n",
    "    - method: str，可选 'mean' 或 'weighted'\n",
    "    - k: int，使用多少个邻居来进行插值\n",
    "    - power: int，weighted 模式下的距离幂次，默认为2\n",
    "    \n",
    "    返回：\n",
    "    - y_pred_full: ndarray[n_samples]，完整预测向量\n",
    "    \"\"\"\n",
    "\t\n",
    "    y_hat_df = pd.DataFrame(y_hat).reset_index()\n",
    "    y_hat_df.columns = ['ori_idx', 'predy']\n",
    "    \n",
    "    n_samples = coords.shape[0]\n",
    "    y_pred_full = np.full(n_samples, np.nan)\n",
    "\n",
    "    known_indices = y_hat_df['ori_idx'].values\n",
    "    y_pred_full[known_indices] = y_hat_df['predy'].values\n",
    "\n",
    "    known_coords = coords[known_indices]\n",
    "    known_preds = y_hat_df['predy'].values\n",
    "\n",
    "    # 构建 KNN 模型用于寻找最近邻（只考虑有预测值的点）\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(known_coords)\n",
    "\n",
    "    # 找到所有缺失点\n",
    "    all_indices = np.arange(n_samples)\n",
    "    missing_indices = np.setdiff1d(all_indices, known_indices)\n",
    "    missing_coords = coords[missing_indices]\n",
    "\n",
    "    # 找出每个缺失点的 k 个邻居\n",
    "    distances, indices = nbrs.kneighbors(missing_coords)\n",
    "\n",
    "    for i, idx in enumerate(missing_indices):\n",
    "        neighbor_preds = known_preds[indices[i]]\n",
    "        if method == 'mean':\n",
    "            y_pred_full[idx] = np.mean(neighbor_preds)\n",
    "        elif method == 'weighted':\n",
    "            d = distances[i]\n",
    "            # 防止距离为0\n",
    "            d[d == 0] = 1e-6\n",
    "            weights = 1 / np.power(d, power)\n",
    "            y_pred_full[idx] = np.sum(weights * neighbor_preds) / np.sum(weights)\n",
    "        else:\n",
    "            raise ValueError(\"method must be 'mean' or 'weighted'\")\n",
    "\n",
    "    return y_pred_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "888b6d8f-974f-4a53-bcf6-cb5ddb43bba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Final Model Fitting with k_nearest = 250 ---\n",
      "Mode: OOF. Using 100 cluster centers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training strategy: K-Fold CV (OOF)\n",
      "fitting time 653.9310035705566\n",
      "\n",
      "--- Evaluating OOF Performance ---\n",
      "Evaluating using OOF predictions...\n",
      "Evaluation - MSE: 1.1493, R²: 0.8484\n",
      "Final OOF Mean Squared Error: 1.1493\n",
      "Final OOF R-squared: 0.8484\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gwr_trainer_known_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal OOF R-squared: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 4. 获取OOF预测结果\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 预测结果是一个DataFrame，索引是样本编号，值为OOF预测值\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m oof_predictions_df \u001b[38;5;241m=\u001b[39m \u001b[43mgwr_trainer_known_k\u001b[49m\u001b[38;5;241m.\u001b[39mprediction()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOOF Predictions Head:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(oof_predictions_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gwr_trainer_known_k' is not defined"
     ]
    }
   ],
   "source": [
    "feature_name = ['X1', 'X2', 'X3', 'X4']\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gxgb_trainer_known_k = GeoWeightedXGBoostTrainer_1(\n",
    "    data=X,\n",
    "    target=y,\n",
    "    locations=coords,\n",
    "    k_nearest=250,           # 已知的最佳带宽\n",
    "    n_clusters=100,          # 使用100个聚类中心\n",
    "    n_splits=5,              # 5折交叉验证\n",
    "    use_full_sample=False,   # 关键：启用基于聚类的OOF模式\n",
    "    n_jobs=8,\n",
    "    tune_evals=30            # 每个局部模型的调参次数\n",
    ")\n",
    "\n",
    "# 2. 调用 .fit() 进行训练\n",
    "# lightweight_mode=False (默认) 确保执行的是完整的OOF训练，而不是轻量级搜索\n",
    "gxgb_trainer_known_k.fit()\n",
    "\n",
    "end_time_1 = time.time()\n",
    "\n",
    "print(f'fitting time {end_time_1 - start_time}')\n",
    "# 3. 评估模型性能\n",
    "# evaluate() 会自动使用OOF预测结果进行评估，因为 use_full_sample=False\n",
    "print(\"\\n--- Evaluating OOF Performance ---\")\n",
    "mse, r2 = gxgb_trainer_known_k.evaluate()\n",
    "if mse is not None:\n",
    "    print(f\"Final OOF Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Final OOF R-squared: {r2:.4f}\")\n",
    "\n",
    "# 4. 获取OOF预测结果\n",
    "# 预测结果是一个DataFrame，索引是样本编号，值为OOF预测值\n",
    "oof_predictions_df = gxgb_trainer_known_k.prediction()\n",
    "print(\"\\nOOF Predictions Head:\")\n",
    "print(oof_predictions_df.head())\n",
    "\n",
    "end_time_2 = time.time()\n",
    "print(f'fitting time {end_time_2 - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11cebec6-43ec-498b-90b3-08d8db6ce6b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2.1: Searching for optimal k_nearest in range (100, 500, 50) ---\n",
      "--- Starting Optimal k_nearest Search ---\n",
      "\n",
      "--- Testing k_nearest = 100 ---\n",
      "Mode: Lightweight search. Using 100 cluster centers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No OOF predictions available to evaluate.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m k_range_to_search \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Step 2.1: Searching for optimal k_nearest in range \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_range_to_search\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m optimal_k \u001b[38;5;241m=\u001b[39m \u001b[43mgwr_trainer_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_optimal_k_nearest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_range_to_search\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# search_optimal_k_nearest 方法会自动将找到的最佳k值设置回实例中\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# gwr_trainer_search.k_nearest 现在已经是 optimal_k\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOptimal k_nearest found and set to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgwr_trainer_search\u001b[38;5;241m.\u001b[39mk_nearest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\Jupyter\\PaperCode\\GW_GeoAI\\M_GWXGB\\M_GWXGB_cluster.py:487\u001b[0m, in \u001b[0;36mGeoWeightedXGBoostTrainer_1.search_optimal_k_nearest\u001b[1;34m(self, k_range)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(lightweight_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m    485\u001b[0m mean_test_error, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmean_test_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_error\u001b[49m:\n\u001b[0;32m    488\u001b[0m     min_error \u001b[38;5;241m=\u001b[39m mean_test_error\n\u001b[0;32m    489\u001b[0m     optimal_k \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "# 初始的 k_nearest 值不重要，因为它会在搜索过程中被覆盖\n",
    "gwr_trainer_search = GeoWeightedXGBoostTrainer_1(\n",
    "    data=X,\n",
    "    target=y,\n",
    "    locations=coords, \n",
    "    n_clusters=100,\n",
    "    n_splits=5,\n",
    "    use_full_sample=False,   # 模式仍然是基于聚类\n",
    "    n_jobs=8,\n",
    "    tune_evals=15            # 在搜索阶段可以减少调参次数以加快速度\n",
    ")\n",
    "\n",
    "# --- 步骤 2.1: 搜索最佳 k_nearest ---\n",
    "# 定义一个搜索范围，例如从100到500，步长为50\n",
    "k_range_to_search = (100, 500, 50)\n",
    "print(f\"\\n--- Step 2.1: Searching for optimal k_nearest in range {k_range_to_search} ---\")\n",
    "optimal_k = gwr_trainer_search.search_optimal_k_nearest(k_range=k_range_to_search)\n",
    "\n",
    "# search_optimal_k_nearest 方法会自动将找到的最佳k值设置回实例中\n",
    "# gwr_trainer_search.k_nearest 现在已经是 optimal_k\n",
    "print(f\"\\nOptimal k_nearest found and set to: {gwr_trainer_search.k_nearest}\")\n",
    "\n",
    "# --- 步骤 2.2: 使用找到的最佳k进行完整的OOF训练 ---\n",
    "print(\"\\n--- Step 2.2: Performing full OOF training with optimal k ---\")\n",
    "# 如果需要，可以增加调参次数以获得更精细的模型\n",
    "gwr_trainer_search.tune_evals = 30 \n",
    "\n",
    "# 直接在同一个实例上调用 .fit() 即可\n",
    "# 此时，它将使用 optimal_k 和完整的OOF模式进行训练\n",
    "gwr_trainer_search.fit() \n",
    "\n",
    "# 3. 评估和获取结果 (同场景1)\n",
    "print(\"\\n--- Evaluating Final OOF Performance ---\")\n",
    "final_mse, final_r2 = gwr_trainer_search.evaluate()\n",
    "if final_mse is not None:\n",
    "    print(f\"Final OOF Mean Squared Error (after search): {final_mse:.4f}\")\n",
    "    print(f\"Final OOF R-squared (after search): {final_r2:.4f}\")\n",
    "\n",
    "final_oof_predictions_df = gwr_trainer_search.prediction()\n",
    "print(\"\\nFinal OOF Predictions Head:\")\n",
    "print(final_oof_predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c02462-035c-4d7e-ba32-5844a404a553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b8e31-d400-4827-9d34-d6800cb4b858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6852568f-6894-471b-96c7-996c2a210758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n",
      "Using 50 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 50 centers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using aggregated test-set predictions on 1466 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2068 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2286 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2402 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2455 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2483 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2495 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2496 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2497 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 125 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2499 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2006 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2386 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2472 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2489 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2495 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2499 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 250 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2309 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2476 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2498 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 375 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2394 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2494 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2498 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2499 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 500 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2452 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2494 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 625 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2464 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2498 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 750 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2480 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2499 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 875 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2491 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 1000 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2493 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 1125 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2495 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 1250 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2496 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 1375 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2498 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 1500 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2499 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1625...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 1625 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 1750 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n",
      "Using 200 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 200 centers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=1875...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 1875 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 2000 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n",
      "Using 100 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 100 centers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2125...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 2125 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 100 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n",
      "Using 150 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 150 centers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 2250 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 50 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n",
      "Using 100 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 100 centers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 150 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 150 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 200 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 250 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 250 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 300 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 350 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 350 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 400 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 400 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 450 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 450 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n",
      "\n",
      "Starting model fitting with use_full_sample=False and k_nearest=2375...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Path\\envs\\py390\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 cluster centers.\n",
      "Finding 2375 nearest neighbors for each of the 500 centers...\n",
      "Evaluating using aggregated test-set predictions on 2500 unique samples...\n"
     ]
    }
   ],
   "source": [
    "## 直接指定带宽\n",
    "\n",
    "bandwidth_list = []\n",
    "cluster_num_list = []\n",
    "r2_list_true = []\n",
    "mse_list_true = []\n",
    "r2_list_interpol = []\n",
    "mse_list_interpol = []\n",
    "y_pred_num_list = []\n",
    "period_list = []\n",
    "\n",
    "for bandwdith in range(125, 2376, 125):\n",
    "    for cluster_num in range(50, 501, 50):\n",
    "\n",
    "        start_time = time.time()\n",
    "        gwxgb_trainer = GeoWeightedXGBoostTrainer(data=X,\n",
    "                                                    target=y,\n",
    "                                                    locations=coords,\n",
    "                                                    n_jobs=8, \n",
    "                                                    use_full_sample = False,\n",
    "                                                    k_nearest=bandwdith, \n",
    "                                                    n_clusters=cluster_num)                          \n",
    "        gwxgb_trainer.fit()\n",
    "        local_y_hat, y_hat = gwxgb_trainer.predict()\n",
    "        mse, r2 = gwxgb_trainer.evaluate_test_set()\n",
    "        bandwidth_list.append(bandwdith)\n",
    "        cluster_num_list.append(cluster_num)\n",
    "        y_pred_num_list.append(len(y_hat))\n",
    "        r2_list_true.append(r2)\n",
    "        mse_list_true.append(mse)\n",
    "            \n",
    "        if len(y_hat) < 2500:\n",
    "            y_pred_full = spatial_interpolator_fill(y_hat, coords)\n",
    "            r2_list_interpol.append(r2_score(y_pred_full, y))\n",
    "            mse_list_interpol.append(mean_squared_error(y_pred_full, y))\n",
    "        else:\n",
    "            r2_list_interpol.append(r2)\n",
    "            mse_list_interpol.append(mse)\n",
    "\n",
    "        end_time = time.time()\n",
    "        period = end_time - start_time\n",
    "        period_list.append(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c3ba3c3-65fb-4ae5-83b6-9bb7987a2d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bw_cluster_df = pd.DataFrame({'bw': bandwidth_list, 'cluster_num': cluster_num_list,\n",
    "                              'r2_true': r2_list_true, \n",
    "                              'r2_interpol': r2_list_interpol, 'mse_interpol': mse_list_interpol, \n",
    "                              'y_pred_len': y_pred_num_list, 'period': period_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f86e34e-1c87-4c79-835c-1933ce1febf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bw</th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>r2_true</th>\n",
       "      <th>r2_interpol</th>\n",
       "      <th>mse_interpol</th>\n",
       "      <th>y_pred_len</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>250</td>\n",
       "      <td>0.823789</td>\n",
       "      <td>0.696866</td>\n",
       "      <td>1.442745</td>\n",
       "      <td>2455</td>\n",
       "      <td>33.721497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>0.820539</td>\n",
       "      <td>0.719291</td>\n",
       "      <td>1.369410</td>\n",
       "      <td>2495</td>\n",
       "      <td>35.939648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>375</td>\n",
       "      <td>250</td>\n",
       "      <td>0.810211</td>\n",
       "      <td>0.810211</td>\n",
       "      <td>1.439009</td>\n",
       "      <td>2500</td>\n",
       "      <td>38.611629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>0.788175</td>\n",
       "      <td>0.788175</td>\n",
       "      <td>1.606092</td>\n",
       "      <td>2500</td>\n",
       "      <td>39.987272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>625</td>\n",
       "      <td>250</td>\n",
       "      <td>0.772100</td>\n",
       "      <td>0.772100</td>\n",
       "      <td>1.727971</td>\n",
       "      <td>2500</td>\n",
       "      <td>40.871955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>750</td>\n",
       "      <td>250</td>\n",
       "      <td>0.756468</td>\n",
       "      <td>0.756468</td>\n",
       "      <td>1.846492</td>\n",
       "      <td>2500</td>\n",
       "      <td>41.432457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>875</td>\n",
       "      <td>250</td>\n",
       "      <td>0.743021</td>\n",
       "      <td>0.743021</td>\n",
       "      <td>1.948450</td>\n",
       "      <td>2500</td>\n",
       "      <td>41.882589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1000</td>\n",
       "      <td>250</td>\n",
       "      <td>0.725556</td>\n",
       "      <td>0.725556</td>\n",
       "      <td>2.080872</td>\n",
       "      <td>2500</td>\n",
       "      <td>42.992430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1125</td>\n",
       "      <td>250</td>\n",
       "      <td>0.714403</td>\n",
       "      <td>0.714403</td>\n",
       "      <td>2.165436</td>\n",
       "      <td>2500</td>\n",
       "      <td>42.926432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1250</td>\n",
       "      <td>250</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>2.262734</td>\n",
       "      <td>2500</td>\n",
       "      <td>42.937742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1375</td>\n",
       "      <td>250</td>\n",
       "      <td>0.695267</td>\n",
       "      <td>0.695267</td>\n",
       "      <td>2.310534</td>\n",
       "      <td>2500</td>\n",
       "      <td>43.460363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1500</td>\n",
       "      <td>250</td>\n",
       "      <td>0.684938</td>\n",
       "      <td>0.684938</td>\n",
       "      <td>2.388847</td>\n",
       "      <td>2500</td>\n",
       "      <td>46.038918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1625</td>\n",
       "      <td>250</td>\n",
       "      <td>0.680279</td>\n",
       "      <td>0.680279</td>\n",
       "      <td>2.424173</td>\n",
       "      <td>2500</td>\n",
       "      <td>46.043180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1750</td>\n",
       "      <td>250</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>2.461171</td>\n",
       "      <td>2500</td>\n",
       "      <td>46.547304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1875</td>\n",
       "      <td>250</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>2.497993</td>\n",
       "      <td>2500</td>\n",
       "      <td>44.958415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2000</td>\n",
       "      <td>250</td>\n",
       "      <td>0.666788</td>\n",
       "      <td>0.666788</td>\n",
       "      <td>2.526461</td>\n",
       "      <td>2500</td>\n",
       "      <td>45.104265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2125</td>\n",
       "      <td>250</td>\n",
       "      <td>0.663722</td>\n",
       "      <td>0.663722</td>\n",
       "      <td>2.549714</td>\n",
       "      <td>2500</td>\n",
       "      <td>47.473365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2250</td>\n",
       "      <td>250</td>\n",
       "      <td>0.660813</td>\n",
       "      <td>0.660813</td>\n",
       "      <td>2.571766</td>\n",
       "      <td>2500</td>\n",
       "      <td>48.231637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2375</td>\n",
       "      <td>250</td>\n",
       "      <td>0.656357</td>\n",
       "      <td>0.656357</td>\n",
       "      <td>2.605553</td>\n",
       "      <td>2500</td>\n",
       "      <td>49.240034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bw  cluster_num   r2_true  r2_interpol  mse_interpol  y_pred_len  \\\n",
       "4     125          250  0.823789     0.696866      1.442745        2455   \n",
       "14    250          250  0.820539     0.719291      1.369410        2495   \n",
       "24    375          250  0.810211     0.810211      1.439009        2500   \n",
       "34    500          250  0.788175     0.788175      1.606092        2500   \n",
       "44    625          250  0.772100     0.772100      1.727971        2500   \n",
       "54    750          250  0.756468     0.756468      1.846492        2500   \n",
       "64    875          250  0.743021     0.743021      1.948450        2500   \n",
       "74   1000          250  0.725556     0.725556      2.080872        2500   \n",
       "84   1125          250  0.714403     0.714403      2.165436        2500   \n",
       "94   1250          250  0.701571     0.701571      2.262734        2500   \n",
       "104  1375          250  0.695267     0.695267      2.310534        2500   \n",
       "114  1500          250  0.684938     0.684938      2.388847        2500   \n",
       "124  1625          250  0.680279     0.680279      2.424173        2500   \n",
       "134  1750          250  0.675399     0.675399      2.461171        2500   \n",
       "144  1875          250  0.670543     0.670543      2.497993        2500   \n",
       "154  2000          250  0.666788     0.666788      2.526461        2500   \n",
       "164  2125          250  0.663722     0.663722      2.549714        2500   \n",
       "174  2250          250  0.660813     0.660813      2.571766        2500   \n",
       "184  2375          250  0.656357     0.656357      2.605553        2500   \n",
       "\n",
       "        period  \n",
       "4    33.721497  \n",
       "14   35.939648  \n",
       "24   38.611629  \n",
       "34   39.987272  \n",
       "44   40.871955  \n",
       "54   41.432457  \n",
       "64   41.882589  \n",
       "74   42.992430  \n",
       "84   42.926432  \n",
       "94   42.937742  \n",
       "104  43.460363  \n",
       "114  46.038918  \n",
       "124  46.043180  \n",
       "134  46.547304  \n",
       "144  44.958415  \n",
       "154  45.104265  \n",
       "164  47.473365  \n",
       "174  48.231637  \n",
       "184  49.240034  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw_cluster_df1 = bw_cluster_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0732d4c9-af47-4b2f-b256-a0b823bddbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_cluster_df_next = bw_cluster_df[bw_cluster_df['y_pred_len'] < 2500]\n",
    "\n",
    "bws = bw_cluster_df_next['bw'].values\n",
    "clusters = bw_cluster_df_next['cluster_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a53f6740-bb08-43ea-84cc-e361f1ab3bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 125,  125,  125,  125,  125,  125,  125,  125,  125,  125,  250,\n",
       "        250,  250,  250,  250,  250,  375,  375,  375,  500,  500,  500,\n",
       "        500,  625,  625,  750,  750,  875,  875, 1000, 1125, 1250, 1375,\n",
       "       1500, 1625], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bc71d66-a304-4ea2-8ca2-663ee4760ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500,  50, 100, 150,\n",
       "       200, 250, 300,  50, 100, 150,  50, 100, 150, 200,  50, 100,  50,\n",
       "       100,  50, 100,  50,  50,  50,  50,  50,  50], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "518891a2-3c39-48bc-a220-6a92da6485bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>predy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.262207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.771560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4.795794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.793661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>2494</td>\n",
       "      <td>2.805756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>2495</td>\n",
       "      <td>3.990550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>2496</td>\n",
       "      <td>4.969280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>2498</td>\n",
       "      <td>0.311182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2499</td>\n",
       "      <td>0.749556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     predy\n",
       "0         1  2.702500\n",
       "1         3  2.262207\n",
       "2         4 -0.771560\n",
       "3         5  4.795794\n",
       "4         6  1.793661\n",
       "...     ...       ...\n",
       "2063   2494  2.805756\n",
       "2064   2495  3.990550\n",
       "2065   2496  4.969280\n",
       "2066   2498  0.311182\n",
       "2067   2499  0.749556\n",
       "\n",
       "[2068 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_500 = local_y_hat.groupby(['index'])['predy'].mean().reset_index()\n",
    "y_hat_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a94b47cf-1a34-47ec-9030-6c34f8857a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>predy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.742861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.550641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.701274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.118545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.030738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2495</td>\n",
       "      <td>3.682503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>3.352097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2497</td>\n",
       "      <td>1.251574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2498</td>\n",
       "      <td>-0.165576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>-0.334553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     predy\n",
       "0         0 -0.742861\n",
       "1         1  3.550641\n",
       "2         2  1.701274\n",
       "3         3  4.118545\n",
       "4         4  0.030738\n",
       "...     ...       ...\n",
       "2495   2495  3.682503\n",
       "2496   2496  3.352097\n",
       "2497   2497  1.251574\n",
       "2498   2498 -0.165576\n",
       "2499   2499 -0.334553\n",
       "\n",
       "[2500 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_df = pd.DataFrame(y_hat).reset_index()\n",
    "y_hat_df.columns = ['ori_idx', 'predy']\n",
    "# y_hat_df['pred_avg'] = y_hat_500['predy']\n",
    "\n",
    "y_hat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c2604ed-40c3-4ec9-929f-2bc0650a9a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692370739875727\n"
     ]
    }
   ],
   "source": [
    "obtained_index = y_hat_df['ori_idx'].values\n",
    "\n",
    "print(r2_score(y[obtained_index], y_hat_df['pred_avg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c3d48bf-8f86-4b98-bcea-055453cf6551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692370739875727 1.6611380506818294\n"
     ]
    }
   ],
   "source": [
    "y_pred_full = np.full(2500, np.nan)\n",
    "\n",
    "obtained_index = pd.DataFrame(y_hat).reset_index()['index'].values\n",
    "y_pred_full[obtained_index] = pd.DataFrame(y_hat).reset_index()['predy'].values\n",
    "    \n",
    "mask_known = ~np.isnan(y_pred_full)\n",
    "\n",
    "y_train = y_pred_full[mask_known]\n",
    "\n",
    "r2_known = r2_score(y[mask_known], y_train)\n",
    "mse_know = mean_squared_error(y[mask_known], y_train)\n",
    "\n",
    "print(r2_known, mse_know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c166bf50-90ee-4c69-aaf0-1f1eaedaf40a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 50/50 [00:39<00:00,  1.26trial/s, best loss: 1.1204374465094815]\n",
      "\n",
      "Best parameters found:\n",
      "{'max_depth': 3, 'learning_rate': 0.036508007159701795, 'subsample': 0.8419736360931015, 'colsample_bytree': 0.8469520993779159, 'min_child_weight': 4, 'gamma': 0.05022181386914993, 'reg_alpha': 0.12722975116876362, 'reg_lambda': 0.384758713405933, 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'random_state': 42}\n",
      "\n",
      "Starting 5-Fold CV for OOF predictions (parallel)...\n",
      "\n",
      "--- Training Final Model on Full Data ---\n",
      "Final model training complete.\n"
     ]
    }
   ],
   "source": [
    "xgb_trainer = XGBoostTrainer_1(n_splits=5, random_state=42, n_jobs=4)\n",
    "final_model, _, _, _, _ = xgb_trainer.calcu_oof_and_shap(X[mask_known], y_train, tune=True, max_evals=50)\n",
    "    \n",
    "# 对缺失样本进行预测\n",
    "mask_missing = np.isnan(y_pred_full)\n",
    "X_missing = X[mask_missing]\n",
    "y_missing_pred = final_model.predict(xgb.DMatrix(X_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4d2d495-95fb-4362-abf9-92cf258de962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6085111675863619 2.7587029830337135\n"
     ]
    }
   ],
   "source": [
    "r2_missing = r2_score(y[mask_missing], y_missing_pred)\n",
    "mse_missing = mean_squared_error(y[mask_missing], y_missing_pred)\n",
    "\n",
    "print(r2_missing, mse_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "728c248b-3adb-4f98-ac33-ddad8c7d8aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_full[mask_missing] = y_missing_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "572d58bc-f1c2-44ec-a26f-d337191b32b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8507972709922345"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred_full, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632cf18f-e58c-44d0-b2a2-9af692f3b3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f24f0814-4e1a-44b9-a2c2-bfb06ef1c423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5795553393859016"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a69a11e-39e2-4829-a54d-30aeaefee575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5795553393859016"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred_full, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dc3a5e3-ad93-4f18-9374-4ab9f7b2c97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True, False, False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8dd027-b6b6-464e-a695-750ce1c5967e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b71e5069-5965-4801-9d86-f1e188521c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        nan, -2.4983878 ,         nan,  2.69457885,  4.70055883,\n",
       "        7.75759537])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_full[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88870ca-52eb-47c0-989b-58a271164088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd707305-f93c-4d64-ad2c-81003778f4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fe5926f-b2aa-40c5-80c9-a1ec8ab9bbcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lng</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.662997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.915145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.340030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.793759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.026859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lng         y\n",
       "0  0.0  1.662997\n",
       "1  1.0  1.915145\n",
       "2  2.0  1.340030\n",
       "3  3.0  1.793759\n",
       "4  4.0  1.026859"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'E:\\PaperCode\\S-MGXGB\\SimuResults_S2_1\\data_1.csv')\n",
    "\n",
    "data_mean = data.groupby('lng')['y'].mean()\n",
    "\n",
    "data_mean_df = pd.DataFrame(data_mean)\n",
    "\n",
    "data_mean_df1 = data_mean_df.reset_index()\n",
    "data_mean_df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457702f-ff47-417e-9583-2bce9c0176a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f4be538-4957-4eac-afff-f0ad43b2a7c2",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800b830-7213-460e-944f-d38dcce464b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y, y_hat)))\n",
    "print(\"adj_R2: \", adjusted_r2_score(y, y_hat, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d849e-0d83-492b-bb22-d10813365cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea8ccce6-75ed-4bd9-9e9d-47adc73edecd",
   "metadata": {},
   "source": [
    "## SHAP calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20093b94-27cc-4e77-8524-458f27f4a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices_list = gwxgb_trainer.test_indices_list\n",
    "interpreter = GeoWeightedXGBoostInterpreter(gwxgb_trainer, use_shap=True)\n",
    "\n",
    "shap_values_df = pd.DataFrame()\n",
    "for i, model in enumerate(gwxgb_trainer.models):\n",
    "    test_indices = test_indices_list[i]\n",
    "    X_test = self.data[test_indices]\n",
    "    shap_values = interpreter.calculate_shap_values(model, X_test)\n",
    "    shap_values_df_i = pd.DataFrame(shap_values, columns=[f\"shap_{j}\" for j in range(shap_values.shape[1])])\n",
    "    shap_values_df_i['original_index'] = test_indices\n",
    "    shap_values_df = pd.concat([shap_values_df, shap_values_df_i], ignore_index=True) ## local\n",
    "gwxgb_shap_global = shap_values_df.groupby('original_index')[[f\"shap_{j}\" for j in range(shap_values.shape[1])]].mean().reset_index() ## global\n",
    "\n",
    "global_shap_xs = np.array(gwxgb_shap_global[['shap_0', 'shap_1', 'shap_2', 'shap_3']]).reshape(2500, 4)\n",
    "gwxgb_shap_local = shap_values_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ae27d-0e8c-47bf-b512-88ecc314745d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96aa294e",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e15f466",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0960f-a691-42d0-8fb6-56d5e46d7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 2.2, 0.5, -0.5]\n",
    "locs_Y = [-3.2, -0.6, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                global_shap_xs[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(global_shap_xs[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gwxgb_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe2b57-36ea-4e87-ac79-2f03ad8c8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local relationships\n",
    "\n",
    "point_id = 'the point id'\n",
    "vmin = point_id * optimal_k * 0.3\n",
    "vmax = (point_id+1) * optimal_k * 0.3\n",
    "\n",
    "for i in range(4):\n",
    "    nearest_indices = gwxgb_shap_local[vmin:vmax].original_index\n",
    "    point_1_shap = gwxgb_shap_local[vmin:vmax].loc[:, f'shap_{i}']\n",
    "    point_1_x3 = X[nearest_indices, i]\n",
    "    f = fs[[nearest_indices], i].reshape(-1)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "                point_1_shap,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "               f,\n",
    "               edgecolors = 'k',\n",
    "               alpha=0.6, \n",
    "               s = 3)\n",
    "\n",
    "    plt.legend(['GWXGB curve', 'Actual curve'])\n",
    "\n",
    "    r2 = r2_score(point_1_shap, f)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "    \n",
    "    plt.legend(['GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gwxgb_X{i+1}_nl_local.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ecd52",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686268f-e489-49ab-a582-0160641ada5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0.5, -3, -2.25]\n",
    "vmaxs = [2.2, 3, 3, 2.25]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(moving_wind(global_shap_xs[:, i], X[:, i]), fr'GWXGB: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = moving_wind(global_shap_xs[:, i], X[:, i]).reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gwxgb_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1586e9da",
   "metadata": {},
   "source": [
    "# MGWR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c047530",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef29093-a7cc-47b7-91ff-8a7143bead6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgwr.gwr import GWR, MGWR                                                   \n",
    "from mgwr.sel_bw import Sel_BW\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b572e2-6a50-4ae9-a0f4-68cf4426fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Sel_BW(coords, y, X, multi=True, constant=True, kernel='bisquare', fixed=False)\n",
    "bws = sel.search(verbose=False)\n",
    "result = MGWR(coords, y, X, selector=sel,constant=True, kernel='bisquare', fixed=False).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd0d7e-99b3-42dd-bb11-03837fa05ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162a58a",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40026c6-62ae-42d8-aecb-2bc7bbd05cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y, result.predy)))\n",
    "print(\"adj_R2: \", adjusted_r2_score(y, result.predy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c84418",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6431435-66b2-4230-9cce-61d89a2c757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f2eda",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9ad1a-dce5-49c9-ab6f-3223715871c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 2.2, 0.5, -0.5]\n",
    "locs_Y = [-3.2, -0.6, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                params[:, i+1] * X[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(params[:, i+1] * X[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['MGWR curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwr_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122864b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## local relationships\n",
    "\n",
    "locs_X = [0.5, 2, 0.5, 0.5]\n",
    "locs_Y = [-3.2, -0.6, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    n_neighbors = int(bws[i+1]) \n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', metric='euclidean')\n",
    "    nn.fit(coords)\n",
    "    distances, selected_indices_list = nn.kneighbors(coords)\n",
    "\n",
    "    nearest_indices = selected_indices_list[point_id]\n",
    "    \n",
    "    b = result.params[:, i+1][point_id]\n",
    "    f = fs[[nearest_indices], i].reshape(-1)\n",
    "    point_1_x3 = X[nearest_indices, i]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "                b*point_1_x3,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "               f,\n",
    "               edgecolors = 'k',\n",
    "               alpha=0.6, \n",
    "               s = 3)\n",
    "\n",
    "    plt.legend(['MGWR curve', 'Actual curve'])\n",
    "\n",
    "    r2 = r2_score(b*point_1_x3, f)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "    \n",
    "    plt.legend(['MGWR curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwr_X{i+1}_nl_local.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38781901",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0.5, -3, -2.25]\n",
    "vmaxs = [2.2, 3, 3, 2.25]\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(result.params[:, i+1], fr'MGWR: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = result.params[:, i+1].reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwr_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee37790",
   "metadata": {},
   "source": [
    "# M-GWXGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f966c1",
   "metadata": {},
   "source": [
    "\n",
    "**1. we first generate the results from GWXGB under 19 bandwidth, named like 'shap_values_bw{bandwidth}_global.csv' and 'shap_values_bw{bandwidth}_local.csv' under your path, where the file ending with \"local.csv\" include the shapley values from all sub-models. and the file ending with \"global.csv\" average the output of \"local.csv\" file by the sample id**  \n",
    "**2. we permutate the shap value to generate the best prediction combination**  \n",
    "**3. use LtoG method to identify the local and global estimator**  \n",
    "**4. set the prediction combination to the initialization and use M-GWXGB to iteratively fit data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe38ea-49f7-48da-8bc1-3d5c6f4d77f1",
   "metadata": {},
   "source": [
    "## LtoG approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e01018-2e11-4aad-ab7b-3a959a07c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate prediction for each variable under each bandwidth\n",
    "bandwidths = [i for i in range(125, 2376, 125)]\n",
    "save_dir = r'....\\\\GWXGB_full'\n",
    "\n",
    "mul_gwxgb = M_GWXGB_Initial(data=X, target=y, locations=coords, bandwidths=bandwidths, \n",
    "                             use_shap=True, \n",
    "                             n_jobs=20, \n",
    "                             shap_save_dir=save_dir)\n",
    "\n",
    "mul_gwxgb.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86124407-9adc-4cc2-aab3-bb7c67f19c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## permutation\n",
    "\n",
    "input_files = []\n",
    "for bandwidth in range(125, 2376, 125):\n",
    "    input_files.append(save_dir + '\\\\' f'shap_values_bw{bandwidth}_global.csv')\n",
    "\n",
    "opt_bandwidth = OptimizedBandwidth(X, y, input_files, shap_save_dir=save_dir)\n",
    "best_combination = opt_bandwidth.optimize_bandwidths()\n",
    "\n",
    "bst_gwxgb = best_combination['bst_shap_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605833b-8e93-42b2-88ea-e84ff7c2a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LtoG\n",
    "\n",
    "gw_shap_values = bst_gwxgb[['shap_0', 'shap_1', 'shap_2','shap_3']]\n",
    "final_shap_values = gw_shap_values.copy()\n",
    "model_choice = {}\n",
    "shap_contributions = {}\n",
    "\n",
    "y_pred_current = np.sum(final_shap_values.values, axis=1) + np.mean(y)\n",
    "best_rmse = np.sqrt(mean_squared_error(y, y_pred_current))\n",
    "\n",
    "print(f\"Original RMSE: {best_rmse:.6f}\")\n",
    "\n",
    "for i in range(4):\n",
    "    shap_names = [f'shap_{j}' for j in range(X.shape[1])]\n",
    "    shap_names.pop(i)\n",
    "    y_pred_other = np.sum(final_shap_values[shap_names], axis=1) + np.mean(y)\n",
    "    y_pred_other = np.array(y_pred_other).reshape(-1, 1)\n",
    "    y_leave = y - y_pred_other\n",
    "    X_leave = X[:, i]\n",
    "\n",
    "    xgb_trainer = XGBoostTrainer_1(n_splits=5, random_state=42, n_jobs=20)\n",
    "    final_model, oof_preds, oof_rmse, oof_r2, oof_shap = xgb_trainer.calcu_oof_and_shap(X_leave, y_leave, tune=True, max_evals=50)\n",
    "\n",
    "    temp_shap_values = final_shap_values.copy()\n",
    "    temp_shap_values[f'shap_{i}'] = oof_preds\n",
    "    y_pred_new = np.sum(temp_shap_values.values, axis=1) + np.mean(y)\n",
    "    rmse_new = np.sqrt(mean_squared_error(y, y_pred_new))\n",
    "    r2_new = r2_score(y, y_pred_new)\n",
    "\n",
    "    print(f'\\nthe {i}_th var')\n",
    "    print(\"--- OOF Performance Metrics ---\")\n",
    "    print(f\"Current best RMSE: {best_rmse:.6f}\")\n",
    "    print(f\"New candidate RMSE: {rmse_new:.6f}\")\n",
    "\n",
    "    var_name = f'shap_{i}'\n",
    "    if rmse_new < best_rmse:\n",
    "        print(f'the best model for {i}_th var is xgb')\n",
    "        final_shap_values[var_name] = oof_preds\n",
    "        model_choice[var_name] = 'xgb'\n",
    "        shap_contributions[var_name] = oof_preds\n",
    "        best_rmse = rmse_new\n",
    "        y_pred_current = y_pred_new\n",
    "    else:\n",
    "        print(f'the best model for {i}_th var is geo')\n",
    "        model_choice[var_name] = 'geo'\n",
    "        shap_contributions[var_name] = final_shap_values[var_name].values\n",
    "\n",
    "print(\"\\nfinal model choice:\", model_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ee057-45a7-46b9-a17c-078be0894334",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185409d8-cefe-4897-9dba-16e6b8da5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_learner_types = list(model_choice.values())\n",
    "\n",
    "k_ranges_for_selection = [(125, 2376, 125), (125, 2376, 125), (125, 2376, 125), (125, 2376, 125)]\n",
    "\n",
    "col_names = [f'shap_{i}' for i in range(4)]\n",
    "initial_results = pd.DataFrame({\n",
    "    col: np.array(shap_contributions[col]).flatten()\n",
    "    for col in shap_contributions\n",
    "})\n",
    "\n",
    "shap_names = [f'shap_{j}' for j in range(X.shape[1])]\n",
    "ini_component_preds = np.array(initial_results[shap_names])\n",
    "\n",
    "m_gwxgb = M_GXGB(\n",
    "    data=X,                                                                                                                                                                                                                                                                            \n",
    "    target=y, \n",
    "    locations=coords,\n",
    "    selected_learner_types=selected_learner_types, \n",
    "    k_range=k_ranges_for_selection,\n",
    "    convergence_tol_percent=1,\n",
    "    n_jobs=20,\n",
    "    init_component_predictions=ini_component_preds\n",
    "    )\n",
    "\n",
    "m_gwxgb.fit()\n",
    "\n",
    "# Predict using the fitted M-GWXGB\n",
    "y_hat_mgwxgb = np.sum(m_gwxgb.component_predictions_, axis = 1) + np.mean(y)\n",
    "mgwxgb_global_shap = m_gwxgb.component_predictions_\n",
    "\n",
    "print(m_gwxgb.optimal_bandwidths_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113dae6-821f-4306-b536-5ffbf7de7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgwxgb_local = pd.DataFrame(gam_gb.local_prediction_df)\n",
    "mgwxgb_local.columns = ['shap_0', 'index_1', 'shap_1', 'shap_2', 'index_3', 'shap_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0267648",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b98b6a-88c9-431b-9c6d-b6d826a56392",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgwxgb_rmse = np.sqrt(mean_squared_error(y.ravel(), y_hat_mgwxgb))\n",
    "mgwxgb_r2 = adjusted_r2_score(y.ravel(), y_hat_mgwxgb, 4)\n",
    "\n",
    "print(f\"RMSE: {mgwxgb_rmse:.4f}\")\n",
    "print(f\"Adj_R2: {mgwxgb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75cac2",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1579bda",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa1894-7976-4424-b089-6d23f14b820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 2.2, 0.5, -0.5]\n",
    "locs_Y = [-3.2, -0.6, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                mgwxgb_global_shap[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(mgwxgb_global_shap[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['M-GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwxgb_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148722bf-8e86-44b1-8872-4125f857902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local\n",
    "\n",
    "locs_X = [0.5, 2.2, 0.5, -0.5]\n",
    "locs_Y = [-3.2, -0.6, -3.2, -2]\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    if i in range(2, 5):\n",
    "            \n",
    "        vmin = bws_mgwxgb[i] * 1\n",
    "        vmax = bws_mgwxgb[i] * (1+1)\n",
    "        \n",
    "        nearest_indices = mgwxgb_local[vmin:vmax].loc[:, f'index_{i}']\n",
    "        nearest_indices_1 = nearest_indices.astype(int)\n",
    "        point_1_shap = mgwxgb_local[vmin:vmax].loc[:, f'shap_{i}']\n",
    "        point_1_x3 = X[nearest_indices_1, i]\n",
    "        f = fs[[nearest_indices_1], i].reshape(-1)\n",
    "\n",
    "        plt.scatter(point_1_x3, \n",
    "                    point_1_shap,\n",
    "                    c = 'none',\n",
    "                    edgecolors = 'green',\n",
    "                    alpha=0.6, \n",
    "                    s = 18)\n",
    "\n",
    "        plt.scatter(point_1_x3, \n",
    "                   f,\n",
    "                   edgecolors = 'k',\n",
    "                   alpha=0.6, \n",
    "                   s = 3)\n",
    "\n",
    "        plt.legend(['M-GWXGB curve', 'Actual curve'])\n",
    "\n",
    "        r2 = r2_score(point_1_shap, f)\n",
    "        plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "        plt.legend(['M-GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "        plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "        plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "    else:\n",
    "        plt.scatter(X[:, i], \n",
    "                    mgwxgb_global[f'f{i+1}_hat'],\n",
    "                    c = 'none',\n",
    "                    edgecolors = 'green',\n",
    "                    alpha=0.6, \n",
    "                    s = 18)\n",
    "\n",
    "        plt.scatter(X[:, i], \n",
    "                    fs[:, i], \n",
    "                    c = 'k', \n",
    "                    s = 3, \n",
    "                    alpha = 0.7)\n",
    "\n",
    "        r2 = r2_score(mgwxgb_global[f'f{i+1}_hat'], fs[:, i])\n",
    "        plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "        plt.legend(['M-GWXGB curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "        plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "        plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "    \n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwxgb_X{i+1}_nl_local_1.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52658c9-8b0c-4689-ba29-9c4219a8fad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a2b1ebe-ddd9-4294-a26a-977f593df708",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5753471-9595-44f6-8ee9-465aa1654a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0.5, -3, -2.25]\n",
    "vmaxs = [2.2, 3, 3, 2.25]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(moving_wind(mgwxgb_global_shap[:, i], X[:, i]), fr'M-GWXGB: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = moving_wind(mgwxgb_global_shap[:, i], X[:, i], w = 2).reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'mgwxgb_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0457c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44b57916",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7ec96",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7347a8a-1ebe-431a-a78d-98d2ee3166b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import kneighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e3d560-a708-4026-adcf-526c9c3f5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GCNTrainer:\n",
    "    def __init__(self, input_dim, n_splits=5, random_state=42):\n",
    "        self.input_dim = input_dim\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.best_params = None\n",
    "        self.best_avg_rmse = float('inf')\n",
    "\n",
    "        self.cv_scores = []\n",
    "        self.oof_predictions = None \n",
    "        self.oof_shap_values = None\n",
    "        self.oof_rmse = None\n",
    "        self.oof_r2 = None\n",
    "\n",
    "        self.X_scaler = None \n",
    "        self.y_scaler = None\n",
    "\n",
    "    def _train_fold(self, data, train_mask, val_mask, params):\n",
    "        \"\"\"Trains and evaluates the model for a single fold using specific parameters.\"\"\"\n",
    "        hidden_dim = int(params['hidden_dim'])\n",
    "        lr = params['lr']\n",
    "        num_epochs = int(params['num_epochs'])\n",
    "        dropout_rate = params['dropout_rate']\n",
    "        weight_decay = params['weight_decay']\n",
    "\n",
    "        model = GCNModel(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=1,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        criterion = nn.MSELoss() \n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)[train_mask]\n",
    "            loss = criterion(out, data.y[train_mask].view(-1, 1)) # Ensure target is 2D\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out_scaled = model(data)[val_mask].cpu().numpy()\n",
    "\n",
    "            y_val_scaled_np = data.y[val_mask].cpu().numpy().reshape(-1, 1) \n",
    "\n",
    "            val_out_original = self.y_scaler.inverse_transform(val_out_scaled)\n",
    "            y_val_original = self.y_scaler.inverse_transform(y_val_scaled_np)\n",
    "\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val_original, val_out_original))\n",
    "\n",
    "        return model, val_rmse, val_out_scaled\n",
    "\n",
    "    def _run_cv_for_objective(self, data_for_trial, params):\n",
    "        \"\"\"Runs K-Fold CV for a specific set of hyperparameters and graph structure.\"\"\"\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        fold_rmses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(data_for_trial.x.shape[0]))):\n",
    "            train_mask = torch.zeros(data_for_trial.x.shape[0], dtype=torch.bool)\n",
    "            val_mask = torch.zeros(data_for_trial.x.shape[0], dtype=torch.bool)\n",
    "            train_mask[train_idx] = True\n",
    "            val_mask[val_idx] = True\n",
    "\n",
    "            try:\n",
    "                 _, fold_rmse, _ = self._train_fold(data_for_trial, train_mask, val_mask, params)\n",
    "                 fold_rmses.append(fold_rmse)\n",
    "            except Exception as e:\n",
    "                 print(f\"Error training fold {fold+1} with params {params}: {e}\")\n",
    "                 return float('inf')\n",
    "\n",
    "        if not fold_rmses:\n",
    "            return float('inf')\n",
    "\n",
    "        avg_rmse = np.mean(fold_rmses)\n",
    "        return avg_rmse\n",
    "\n",
    "    def objective(self, params, X_tensor_scaled, y_tensor, coords, X_scaler, y_scaler):\n",
    "        \"\"\"Objective function for Hyperopt Bayesian Optimization.\"\"\"\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "        n_neighbors = int(params['n_neighbors'])\n",
    "        try:\n",
    "            graph = kneighbors_graph(coords, n_neighbors=n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "            edge_index = torch.tensor(np.array(graph.nonzero()), dtype=torch.long).contiguous() \n",
    "            data_for_trial = Data(x=X_tensor_scaled, edge_index=edge_index, y=y_tensor)\n",
    "        \n",
    "        except Exception as e:\n",
    "             print(f\"Error building graph with n_neighbors={n_neighbors}: {e}\")\n",
    "             return {'loss': float('inf'), 'status': STATUS_OK}\n",
    "\n",
    "        avg_cv_rmse = self._run_cv_for_objective(data_for_trial, params)\n",
    "\n",
    "        return {'loss': avg_cv_rmse, 'status': STATUS_OK}\n",
    "\n",
    "    def bayes_optimize(self, X_tensor_scaled, y_tensor, coords, X_scaler, y_scaler, search_space, max_evals=50):\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "        trials = Trials()\n",
    "\n",
    "        best = fmin(\n",
    "            fn=lambda params: self.objective(params, X_tensor_scaled, y_tensor, coords, X_scaler, y_scaler),\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(self.random_state)\n",
    "        )\n",
    "\n",
    "        self.best_params = {\n",
    "            'hidden_dim': int(best['hidden_dim']),\n",
    "            'lr': best['lr'],\n",
    "            'num_epochs': int(best['num_epochs']),\n",
    "            'dropout_rate': best['dropout_rate'],\n",
    "            'weight_decay': best['weight_decay'],\n",
    "            'n_neighbors': int(best['n_neighbors'])\n",
    "        }\n",
    "\n",
    "        print(\"\\nRe-evaluating best parameters to get final CV RMSE...\")\n",
    "        best_n_neighbors = int(self.best_params['n_neighbors'])\n",
    "        graph_best = kneighbors_graph(coords, n_neighbors=best_n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "        edge_index_best = torch.tensor(np.array(graph_best.nonzero()), dtype=torch.long).contiguous()\n",
    "        data_best_graph = Data(x=X_tensor_scaled, edge_index=edge_index_best, y=y_tensor)\n",
    "\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "        self.best_avg_rmse = self._run_cv_for_objective(data_best_graph, self.best_params)\n",
    "\n",
    "        print(\"\\nBayesian Optimization complete.\")\n",
    "        print(f\"Best Hyperparameters found: {self.best_params}\")\n",
    "        print(f\"Best Average CV RMSE from Re-evaluation: {self.best_avg_rmse:.4f}\")\n",
    "        return self.best_params, self.best_avg_rmse\n",
    "\n",
    "    def predict_for_shap(self, x_np_batch, model, X_scaler, y_scaler, n_neighbors):\n",
    "\n",
    "        model.eval()\n",
    "        x_np_batch = x_np_batch.astype(np.float32)\n",
    "\n",
    "        try:\n",
    "             coords_batch = x_np_batch[:, :2]\n",
    "             if coords_batch.shape[0] <= n_neighbors:\n",
    "                return np.full(x_np_batch.shape[0], np.nan)\n",
    "\n",
    "             graph = kneighbors_graph(coords_batch, n_neighbors=n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "             edge_index_batch = torch.tensor(np.array(graph.nonzero()), dtype=torch.long).contiguous() # Ensure contiguous\n",
    "        except Exception as e:\n",
    "             print(f\"Unexpected error building graph for SHAP with n_neighbors={n_neighbors}, batch shape {x_np_batch.shape}: {e}\")\n",
    "             return np.full(x_np_batch.shape[0], np.nan)\n",
    "\n",
    "        x_tensor_scaled = torch.tensor(X_scaler.transform(x_np_batch), dtype=torch.float32)\n",
    "\n",
    "        new_data_batch = Data(x=x_tensor_scaled, edge_index=edge_index_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions_scaled = model(new_data_batch).detach().cpu().numpy() # Move to CPU\n",
    "\n",
    "            predictions_original = y_scaler.inverse_transform(predictions_scaled)\n",
    "\n",
    "        return predictions_original.flatten()\n",
    "\n",
    "    def calculate_oof_and_shap(self, X_tensor_scaled, y_tensor, coords, X_original_np, y_original_np, X_scaler, y_scaler, feature_names):\n",
    "\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"Best parameters not set. Run bayes_optimize first.\")\n",
    "\n",
    "        # Store scalers\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "        best_n_neighbors = int(self.best_params['n_neighbors'])\n",
    "        print(f\"\\nBuilding final graph for OOF run with best n_neighbors: {best_n_neighbors}\")\n",
    "        try:\n",
    "             graph = kneighbors_graph(coords, n_neighbors=best_n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "             edge_index_final = torch.tensor(np.array(graph.nonzero()), dtype=torch.long).contiguous() # Ensure contiguous\n",
    "             data_final = Data(x=X_tensor_scaled, edge_index=edge_index_final, y=y_tensor)\n",
    "             print(f\"Final graph built with {edge_index_final.shape[1]} edges.\")\n",
    "        except Exception as e:\n",
    "            print(f\"FATAL ERROR: Could not build final graph with n_neighbors={best_n_neighbors}: {e}\")\n",
    "            self.oof_rmse, self.oof_r2 = np.nan, np.nan\n",
    "            return np.full(X_original_np.shape[0], np.nan), np.full(X_original_np.shape, np.nan), self.oof_rmse, self.oof_r2, np.zeros(X_original_np.shape[0], dtype=bool)\n",
    "\n",
    "        print(f\"\\nStarting {self.n_splits}-Fold CV for OOF predictions and SHAP values using best params...\")\n",
    "\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "\n",
    "        self.oof_predictions = np.zeros(X_original_np.shape[0])\n",
    "        self.oof_shap_values = np.zeros(X_original_np.shape)\n",
    "        self.cv_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(data_final.x.shape[0]))):\n",
    "            print(f\"\\n--- Processing Fold {fold+1}/{self.n_splits} ---\")\n",
    "\n",
    "            train_mask = torch.zeros(data_final.x.shape[0], dtype=torch.bool)\n",
    "            val_mask = torch.zeros(data_final.x.shape[0], dtype=torch.bool)\n",
    "            train_mask[train_idx] = True\n",
    "            val_mask[val_idx] = True\n",
    "\n",
    "            fold_model, fold_val_rmse, val_out_scaled = self._train_fold(data_final, train_mask, val_mask, self.best_params)\n",
    "            self.cv_scores.append(fold_val_rmse)\n",
    "            print(f\"Fold {fold+1} Validation RMSE: {fold_val_rmse:.4f}\")\n",
    "\n",
    "            val_preds_original = self.y_scaler.inverse_transform(val_out_scaled)\n",
    "            self.oof_predictions[val_idx] = val_preds_original.flatten() # Ensure 1D\n",
    "\n",
    "            X_val_fold_np = X_original_np[val_idx] \n",
    "\n",
    "            if len(X_val_fold_np) > 0:\n",
    "                # Instantiate SHAP Explainer\n",
    "                print(f\"Calculating SHAP values for {len(val_idx)} validation nodes in Fold {fold+1} using best n_neighbors={best_n_neighbors}...\")\n",
    "                try:\n",
    "                     explainer = shap.Explainer(\n",
    "                         lambda x_batch: self.predict_for_shap(x_batch, fold_model, self.X_scaler, self.y_scaler, best_n_neighbors),\n",
    "                         X_original_np[train_idx], \n",
    "                         feature_names=feature_names \n",
    "                     )\n",
    "\n",
    "                     shap_values_fold = explainer(X_val_fold_np).values\n",
    "                     print(f\"Finished SHAP calculation for Fold {fold+1}.\")\n",
    "\n",
    "                     self.oof_shap_values[val_idx, :] = shap_values_fold\n",
    "\n",
    "                except Exception as e:\n",
    "                     print(f\"SHAP calculation failed for Fold {fold+1}: {e}\")\n",
    "                     print(\"Storing NaNs for SHAP values in this fold.\")\n",
    "                     self.oof_shap_values[val_idx, :] = np.full_like(self.oof_shap_values[val_idx, :], np.nan)\n",
    "\n",
    "            else:\n",
    "                 print(f\"  Fold {fold+1} validation set is empty. Skipping SHAP calculation.\")\n",
    "\n",
    "        print(\"\\n5-Fold CV and SHAP calculation complete.\")\n",
    "\n",
    "        valid_nodes_for_oof = ~np.isnan(self.oof_predictions)\n",
    "        shap_row_has_nan = np.isnan(self.oof_shap_values).any(axis=1)\n",
    "        valid_nodes_for_oof = valid_nodes_for_oof & (~shap_row_has_nan)\n",
    "\n",
    "\n",
    "        if valid_nodes_for_oof.sum() > 0:\n",
    "             y_valid = y_original_np[valid_nodes_for_oof]\n",
    "             oof_preds_valid = self.oof_predictions[valid_nodes_for_oof]\n",
    "             oof_shap_valid = self.oof_shap_values[valid_nodes_for_oof]\n",
    "             X_combined_valid = X_original_np[valid_nodes_for_oof]\n",
    "\n",
    "             # Calculate overall OOF metrics on valid nodes\n",
    "             self.oof_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds_valid))\n",
    "             self.oof_r2 = r2_score(y_valid, oof_preds_valid)\n",
    "\n",
    "             print(f\"\\n--- Overall OOF Results (on {valid_nodes_for_oof.sum()} valid nodes) ---\")\n",
    "             print(f\"Overall OOF RMSE: {self.oof_rmse:.4f}\")\n",
    "             print(f\"Overall OOF R2: {self.oof_r2:.4f}\")\n",
    "             print(f\"Average Fold Validation RMSE: {np.mean(self.cv_scores):.4f} (Std: {np.std(self.cv_scores):.4f})\")\n",
    "             return self.oof_predictions, self.oof_shap_values, self.oof_rmse, self.oof_r2, valid_nodes_for_oof, X_combined_valid\n",
    "        else:\n",
    "            print(\"No valid OOF predictions or SHAP values were computed across folds.\")\n",
    "            self.oof_rmse, self.oof_r2 = np.nan, np.nan\n",
    "            return self.oof_predictions, self.oof_shap_values, self.oof_rmse, self.oof_r2, valid_nodes_for_oof, None # Return None for X_combined_valid if no valid nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ad52c-54b3-41a6-85f5-0dfaccd57f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (fit on full X)\n",
    "\n",
    "feature_names = [f'X{i+1}' for i in range(X.shape[1])]\n",
    "X_combined = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_combined_standardized = X_scaler.fit_transform(X)\n",
    "\n",
    "# Standardize target separately\n",
    "y_scaler = StandardScaler()\n",
    "y_standardized = y_scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_tensor_scaled = torch.tensor(X_combined_standardized, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_standardized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38856767-3b8e-45a7-b205-9afe2bd2f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'hidden_dim': hp.quniform('hidden_dim', 16, 128, 1), \n",
    "    'lr': hp.loguniform('lr', np.log(0.00005), np.log(0.01)),\n",
    "    'num_epochs': hp.quniform('num_epochs', 100, 600, 1), \n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.6),\n",
    "    'weight_decay': hp.loguniform('weight_decay', np.log(1e-5), np.log(1e-3)),\n",
    "    'n_neighbors': hp.quniform('n_neighbors', 10, 40, 1) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af19424-0e22-480f-90af-abf4f15d61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInstantiating GCN Trainer...\")\n",
    "gcn_trainer = GCNTrainer(\n",
    "    input_dim=X_combined_standardized.shape[1],\n",
    "    n_splits=5,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Bayesian Optimization...\")\n",
    "start_time_bo = time.time()\n",
    "max_optimization_evals = 50 \n",
    "\n",
    "best_params, best_avg_rmse_opt = gcn_trainer.bayes_optimize(\n",
    "    X_tensor_scaled, y_tensor, coords, X_scaler, y_scaler, search_space, max_evals=max_optimization_evals\n",
    ")\n",
    "end_time_bo = time.time()\n",
    "print(f\"Bayesian Optimization ({max_optimization_evals} evals) took {end_time_bo - start_time_bo:.2f} seconds.\")\n",
    "\n",
    "start_time_oof_shap = time.time()\n",
    "oof_predictions, oof_shap_values, oof_rmse, oof_r2, valid_nodes_for_oof, X_combined_valid = gcn_trainer.calculate_oof_and_shap(\n",
    "    X_tensor_scaled, y_tensor, coords, X, y, X_scaler, y_scaler, feature_names\n",
    ")\n",
    "end_time_oof_shap = time.time()\n",
    "print(f\"OOF prediction and SHAP calculation took {end_time_oof_shap - start_time_oof_shap:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca3b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11cdabd",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a666901-0be1-43ff-b8a9-7fb201eee9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: \", oof_rmse)\n",
    "print(\"adj_R2: \", adjusted_r2_score(oof_predictions, y, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd62b0c",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87524f1d",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec95cb0-794a-481b-920d-d487d3cfba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global\n",
    "locs_X = [0.5, 2.2, 0.5, -0.5]\n",
    "locs_Y = [-7, -6, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                oof_shap_values[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(oof_shap_values[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GCN curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gcn_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d699ec-e720-47a1-9d95-d9ab079ac428",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local\n",
    "\n",
    "x_test = np.random.uniform(-1.5, 1.5, 2500)\n",
    "f_test = - x_test ** 3\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    b = oof_shap_values[:, i][point_id] / X[:, i][point_id]\n",
    "    plt.scatter(x_test, \n",
    "                b*x_test,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(x_test, \n",
    "                f_test, \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(b*x_test, f_test)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GCN curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\phi_{i+1} (X_{i+1})$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gcn_X{i+1}_nl_local_1.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553aec5",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73b806-f30d-47b4-9e2f-b1bd5f7c369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0.5, -3, -2.25]\n",
    "vmaxs = [2.2, 3, 3, 2.25]\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(moving_wind(oof_shap_values[:, i], X[:, i]), fr'GCN: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = moving_wind(oof_shap_values[:, i], X[:, i]).reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'gcn_X{i+1}_s.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46f393",
   "metadata": {},
   "source": [
    "# GGP-GAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d94ca",
   "metadata": {},
   "source": [
    "## GGP_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d3e5e-fb8b-4758-aca6-2f3981de18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp_results = pd.read_csv(save_dir + '\\\\' + r'ggp_gam_svc_all_location_results.csv') ## generated by R code\n",
    "\n",
    "ggp_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d93c01",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a629d-7211-4bd4-93e0-62d74fe52bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(ggp_results['predicted_y_svc_all']).reshape(-1, 1)\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print(\"adj_R2: \", adjusted_r2_score(y, result.predy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454529f7",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa132a-eae4-40ed-919c-9bf9adb21ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.array(ggp_results[['estimated_beta_X1', 'estimated_beta_X2', 'estimated_beta_X3', 'estimated_beta_X4']]).reshape(2500, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df282f28-183d-4173-acb2-b1ffb914c73f",
   "metadata": {},
   "source": [
    "### Non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00400af5-f6e3-493f-8a09-7f6bec621f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 2.2, 0.5, -0.5]\n",
    "locs_Y = [-3.2, -0.6, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                betas[:, i] * X[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(betas[:, i] * X[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GGP-GAM curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'ggp_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e2b7f-296d-4d9d-87a4-075010bd25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local relationships\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                betas[:, i] * X[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(betas[:, i] * X[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['GGP-GAM curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'ggp_X{i+1}_nl_local.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d6f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b9266c",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737e9e6-edd1-469a-84b4-930525873b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0.5, -3, -2.25]\n",
    "vmaxs = [2.2, 3, 3, 2.25]\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(betas[:, i], fr'GGP-GAM: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = betas[:, i].reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'ggp_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eafe97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66fef420",
   "metadata": {},
   "source": [
    "# S-GWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33723eb0-dea5-480a-986f-35c5434c7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgwr_results = pd.read_csv(save_path + '\\\\' + r'S_GWR_listwise.csv')\n",
    "sgwr_results[' est_x1'] = 2.015515   ## extract from the \"txt\" file generated by the GWR 4.0 Software\n",
    "sgwr_results[' est_x2'] = 0.540782\n",
    "sgwr_results[' est_x3'] = 1.332049\n",
    "sgwr_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05caf4b3",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d11e4c-6de0-4095-a5ba-37cc3ab20a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(sgwr_results[' yhat']).reshape(-1, 1)\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print(\"adj_R2: \", adjusted_r2_score(y, y_pred, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f1a9a-b1f0-4e10-a880-a9c50576c585",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e4621-be14-4977-ad16-498e6033a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.array(sgwr_results[[' est_x1', ' est_x2', ' est_x3', ' est_x4']]).reshape(2500, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccafdb1",
   "metadata": {},
   "source": [
    "### 非线性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf3b6f-5ebe-4267-9c6d-cfa7aa982698",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global relationships\n",
    "locs_X = [0.5, 2.2, 0.5, -0.5]\n",
    "locs_Y = [-3.2, -0.6, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.scatter(X[:, i], \n",
    "                betas[:, i] * X[:, i],\n",
    "                c = 'none',\n",
    "                edgecolors = 'darkred',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "    \n",
    "    plt.scatter(X[:, i], \n",
    "                fs[:, i], \n",
    "                c = 'k', \n",
    "                s = 3, \n",
    "                alpha = 0.7)\n",
    "    \n",
    "    r2 = r2_score(params[:, i] * X[:, i], fs[:, i])\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "\n",
    "    plt.legend(['S-GWR curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'sgwr_X{i+1}_nl.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd52f1-0ddf-48c2-98f9-d4c9fd618769",
   "metadata": {},
   "outputs": [],
   "source": [
    "## local relationships\n",
    "\n",
    "locs_X = [0.5, 2, 0.5, 0.5]\n",
    "locs_Y = [-3.2, -0.6, -3.2, -3]\n",
    "locs = ['upper left', 'upper left', 'upper center','upper center', 'upper left']\n",
    "\n",
    "n_neighbors = 116 \n",
    "nn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', metric='euclidean')\n",
    "nn.fit(coords)\n",
    "distances, selected_indices_list = nn.kneighbors(coords)\n",
    "\n",
    "nearest_indices = selected_indices_list[point_id]\n",
    "\n",
    "for i in range(4):\n",
    "        \n",
    "    b = betas[:, i][point_id]\n",
    "    f = fs[[nearest_indices], i].reshape(-1)\n",
    "    point_1_x3 = X[nearest_indices, i]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "                b*point_1_x3,\n",
    "                c = 'none',\n",
    "                edgecolors = 'green',\n",
    "                alpha=0.6, \n",
    "                s = 18)\n",
    "\n",
    "    plt.scatter(point_1_x3, \n",
    "               f,\n",
    "               edgecolors = 'k',\n",
    "               alpha=0.6, \n",
    "               s = 3)\n",
    "\n",
    "    plt.legend(['S-GWR curve', 'Actual curve'])\n",
    "\n",
    "    r2 = r2_score(b*point_1_x3, f)\n",
    "    plt.text(locs_X[i], locs_Y[i], '$R^2$: %s' %(round(r2, 3)), fontdict={'size':32})\n",
    "    \n",
    "    plt.legend(['S-GWR curve', 'Actual curve'], loc = locs[i])\n",
    "\n",
    "    plt.ylabel(fr'$\\beta_{i+1} X_{i+1}$')\n",
    "    plt.xlabel(fr'$\\mathrm{{X}}_{i+1}$')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'sgwr_X{i+1}_nl_local.jpg', \n",
    "                dpi = 300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee68af8",
   "metadata": {},
   "source": [
    "### Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760498cb-ac03-4a7c-8550-1ff506feb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmins = [1.8, 0.5, -3, -2.25]\n",
    "vmaxs = [2.2, 3, 3, 2.25]\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "\n",
    "    plot_1(betas[:, i], fr'S-GWR: $f_{i+1} $', vmin = vmins[i], vmax = vmaxs[i])\n",
    "    \n",
    "    expected = fs[:, i] / X[:, i].reshape(-1)\n",
    "    predicted = betas[:, i].reshape(-1)\n",
    "    cosine_sim = np.dot(predicted, expected)/(np.linalg.norm(predicted) * np.linalg.norm(expected))\n",
    "    \n",
    "    print(f'the cosine similarity index for x_{i+1} is {cosine_sim}')\n",
    "\n",
    "    plt.savefig(save_path + '\\\\' + fr'sgwr_X{i+1}_s.jpg', \n",
    "                dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0391e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2d2c7-012d-4b39-8c9e-3290b4eff5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "\n",
    "for bandwidth in range(125, 2376, 125):\n",
    "\n",
    "    start_time = time.time()\n",
    "    geo_trainer = GeoWeightedXGBoostTrainer(\n",
    "        X, \n",
    "        y, \n",
    "        coords,\n",
    "        use_full_sample=False, # 设定最终的训练模式\n",
    "        n_clusters=100,\n",
    "        k_nearest=bandwidth,\n",
    "        n_jobs=-1\n",
    "    )   \n",
    "\n",
    "    geo_trainer.fit()\n",
    "\n",
    "    mse, r2_value = geo_trainer.evaluate()\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    r2_list.append(r2_value)\n",
    "\n",
    "    end_time = time.time()\n",
    "    period_time = end_time - start_time\n",
    "    print(period_time)\n",
    "\n",
    "\n",
    "print(f'mse values: {mse_list}')\n",
    "print(f'r2 values: {r2_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04828275-8728-4cc3-a181-0813a25ad042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53ef457d-f3f7-4d6f-9037-7a1ca984e11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.162549</td>\n",
       "      <td>0.336511</td>\n",
       "      <td>-0.019114</td>\n",
       "      <td>-0.294332</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.673021</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.081358e-16</td>\n",
       "      <td>-0.299573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341259</td>\n",
       "      <td>-0.992791</td>\n",
       "      <td>-0.286502</td>\n",
       "      <td>1.381216</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.985581</td>\n",
       "      <td>-0.008682</td>\n",
       "      <td>2.627975e-01</td>\n",
       "      <td>-0.299573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.377965</td>\n",
       "      <td>-0.191823</td>\n",
       "      <td>0.178069</td>\n",
       "      <td>0.059899</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.383646</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>2.297591e-02</td>\n",
       "      <td>-0.299573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.965798</td>\n",
       "      <td>0.807787</td>\n",
       "      <td>0.833617</td>\n",
       "      <td>0.796014</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.615575</td>\n",
       "      <td>0.075783</td>\n",
       "      <td>4.610012e-01</td>\n",
       "      <td>-0.299573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.586662</td>\n",
       "      <td>-0.614024</td>\n",
       "      <td>-1.190700</td>\n",
       "      <td>0.982412</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.228048</td>\n",
       "      <td>-0.144327</td>\n",
       "      <td>7.623870e-01</td>\n",
       "      <td>-0.299573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y        x1        x2        x3   x4  lng  lat        f1        f2  \\\n",
       "0  2.162549  0.336511 -0.019114 -0.294332  0.1  0.0  0.0  0.673021 -0.000000   \n",
       "1  0.341259 -0.992791 -0.286502  1.381216  0.1  1.0  0.0 -1.985581 -0.008682   \n",
       "2  2.377965 -0.191823  0.178069  0.059899  0.1  2.0  0.0 -0.383646  0.010792   \n",
       "3  2.965798  0.807787  0.833617  0.796014  0.1  3.0  0.0  1.615575  0.075783   \n",
       "4  1.586662 -0.614024 -1.190700  0.982412  0.1  4.0  0.0 -1.228048 -0.144327   \n",
       "\n",
       "             f3        f4  \n",
       "0  1.081358e-16 -0.299573  \n",
       "1  2.627975e-01 -0.299573  \n",
       "2  2.297591e-02 -0.299573  \n",
       "3  4.610012e-01 -0.299573  \n",
       "4  7.623870e-01 -0.299573  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'E:\\PaperCode\\S-MGXGB\\SimuResults_S2_1\\data_1.csv')\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edcb4882-619f-44c2-b6a5-279cadce3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = data.groupby('lng')['x1'].mean()\n",
    "\n",
    "data_mean_df = pd.DataFrame({'data_mean': data_mean})\n",
    "\n",
    "data_mean_df_1 = pd.DataFrame(data_mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6788641-3ddf-4664-97ed-a0ed97cd5b4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lng</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.113318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.181372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>-0.130977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.131323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>-0.070949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>-0.157534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.030713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>-0.029396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>-0.017741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>-0.049161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.133872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>-0.051485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.042842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>0.136391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>0.031754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>-0.119040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>-0.007992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>0.050528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>-0.059339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>0.193928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>-0.017794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0.184178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>0.042474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>0.255428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>0.094255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>-0.083850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>-0.055285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>-0.159072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>-0.248074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>0.114849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.133069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.0</th>\n",
       "      <td>0.139756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.0</th>\n",
       "      <td>-0.145009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.0</th>\n",
       "      <td>-0.175008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <td>-0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>0.170370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>0.125318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>0.254497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.0</th>\n",
       "      <td>-0.143764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>-0.012893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>-0.040798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.0</th>\n",
       "      <td>0.012427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>-0.013250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.0</th>\n",
       "      <td>0.052267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44.0</th>\n",
       "      <td>-0.044488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>0.084970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.0</th>\n",
       "      <td>-0.124852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.0</th>\n",
       "      <td>-0.010303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.0</th>\n",
       "      <td>0.088664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.0</th>\n",
       "      <td>0.046437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_mean\n",
       "lng            \n",
       "0.0    0.113318\n",
       "1.0    0.181372\n",
       "2.0   -0.130977\n",
       "3.0    0.131323\n",
       "4.0   -0.070949\n",
       "5.0   -0.157534\n",
       "6.0    0.030713\n",
       "7.0   -0.029396\n",
       "8.0   -0.017741\n",
       "9.0   -0.049161\n",
       "10.0   0.133872\n",
       "11.0  -0.051485\n",
       "12.0   0.042842\n",
       "13.0   0.136391\n",
       "14.0   0.031754\n",
       "15.0  -0.119040\n",
       "16.0  -0.007992\n",
       "17.0   0.050528\n",
       "18.0  -0.059339\n",
       "19.0   0.193928\n",
       "20.0  -0.017794\n",
       "21.0   0.184178\n",
       "22.0   0.042474\n",
       "23.0   0.255428\n",
       "24.0   0.094255\n",
       "25.0  -0.083850\n",
       "26.0  -0.055285\n",
       "27.0  -0.159072\n",
       "28.0  -0.248074\n",
       "29.0   0.114849\n",
       "30.0   0.133069\n",
       "31.0   0.139756\n",
       "32.0  -0.145009\n",
       "33.0  -0.175008\n",
       "34.0  -0.000032\n",
       "35.0   0.170370\n",
       "36.0   0.125318\n",
       "37.0   0.254497\n",
       "38.0  -0.143764\n",
       "39.0  -0.012893\n",
       "40.0  -0.040798\n",
       "41.0   0.012427\n",
       "42.0  -0.013250\n",
       "43.0   0.052267\n",
       "44.0  -0.044488\n",
       "45.0   0.084970\n",
       "46.0  -0.124852\n",
       "47.0  -0.010303\n",
       "48.0   0.088664\n",
       "49.0   0.046437"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be880236-581e-4721-b3c7-e9913c683f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309.9px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
